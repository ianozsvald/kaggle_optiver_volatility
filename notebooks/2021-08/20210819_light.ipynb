{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c8b07f27-26af-4f9f-a474-4f4ed0a155a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENV_HOME: True, TEST_SIZE 0.25, USE_ALL_STOCK_IDS True, USE_TEST_LOCAL_6_ITEMS False\n",
      "NBR_FOR_SUBSET_OF_STOCK_IDS: None\n",
      "In [176] used 0.0312 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 2033.64 MiB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "from numpy.random import default_rng\n",
    "RANDOM_STATE = 2 # random state for default_rng\n",
    "rng = default_rng(RANDOM_STATE)\n",
    "\n",
    "\n",
    "import random\n",
    "#import altair as alt\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "# CHECKLIST for Kaggle variant\n",
    "# USE_ALL_STOCK_IDS False to check then True\n",
    "# USE_TEST_LOCAL_6_ITEMS must be False else we override the local test data\n",
    "# TEST_SIZE must be 0 to get all items\n",
    "# Check on Kaggle that \"internet\" is disabled\n",
    "# First run with \"USE_ALL_STOCK_IDS=False\", flip to True, Save Version, it'll take 30 mins to run\n",
    "\n",
    "# CHECKLIST for home variant\n",
    "# USE_ALL_STOCK_IDS False for fast dev, True for proper testing\n",
    "# USE_TEST_LOCAL_6_ITEMS False for fast dev, True for proper testing\n",
    "# NBR_FOR_SUBSET_OF_STOCK_IDS 4 for quick testing\n",
    "\n",
    "t1_notebook_start = datetime.datetime.utcnow()\n",
    "\n",
    "if os.environ.get('USER') == 'ian':\n",
    "    ENV_HOME = True\n",
    "    import ipython_memory_usage\n",
    "    %ipython_memory_usage_start\n",
    "    USE_ALL_STOCK_IDS = True\n",
    "    NBR_FOR_SUBSET_OF_STOCK_IDS = 4\n",
    "    TEST_SIZE = 0.25 # for single train/test split\n",
    "    #USE_TEST_LOCAL_6_ITEMS = True # robust local testing at home\n",
    "    USE_TEST_LOCAL_6_ITEMS = False # robust local testing at home TEMPORARY WHILST DEBUGGING\n",
    "    \n",
    "    from joblib import Memory\n",
    "    memory = Memory(location='joblib_cache', verbose=0)\n",
    "\n",
    "else:\n",
    "    ENV_HOME = False\n",
    "    USE_ALL_STOCK_IDS = False # for KAGGLE on first-upload for a quick test\n",
    "    TEST_SIZE = 0\n",
    "    USE_TEST_LOCAL_6_ITEMS = False\n",
    "    NBR_FOR_SUBSET_OF_STOCK_IDS = 4\n",
    "    # kaggle notes:\n",
    "    # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "    # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "\n",
    "if USE_ALL_STOCK_IDS:\n",
    "    NBR_FOR_SUBSET_OF_STOCK_IDS=None\n",
    "print(f'ENV_HOME: {ENV_HOME}, TEST_SIZE {TEST_SIZE}, USE_ALL_STOCK_IDS {USE_ALL_STOCK_IDS}, USE_TEST_LOCAL_6_ITEMS {USE_TEST_LOCAL_6_ITEMS}')\n",
    "print(f'NBR_FOR_SUBSET_OF_STOCK_IDS: {NBR_FOR_SUBSET_OF_STOCK_IDS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a686d343-962d-45ab-90d1-cfeaf5a310c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [177] used 0.0000 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 2033.64 MiB\n"
     ]
    }
   ],
   "source": [
    "# OR PASTE IN UTILITY CODE HERE FOR KAGGLE\n",
    "from utility import make_unique_time_ids, get_training_stock_ids, rmspe_score\n",
    "from utility import ROOT, TEST_CSV, TRAIN_CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bebae2-9f9f-44b4-ac8a-6681b4866674",
   "metadata": {},
   "source": [
    "## Load train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f31ca1bb-a43b-4847-b3d7-dde9ecb027be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[59, 58, 23]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [178] used 0.0078 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 2033.64 MiB\n"
     ]
    }
   ],
   "source": [
    "stock_ids = get_training_stock_ids('book_train.parquet') # all stocks by default\n",
    "\n",
    "if not USE_ALL_STOCK_IDS:\n",
    "    # choose a random subset\n",
    "    print(f\"Using a subset of {NBR_FOR_SUBSET_OF_STOCK_IDS}\")\n",
    "    rng.shuffle(stock_ids)\n",
    "    #random.shuffle(stock_ids)\n",
    "    stock_ids = stock_ids[:NBR_FOR_SUBSET_OF_STOCK_IDS]\n",
    "else:\n",
    "    print(\"Using all\")\n",
    "stock_ids[:3] # expect 59, 58, 23 if we're using all or 76, 73, 0 on the RANDOM_STATE of 1 if we don't use all stock ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "333d41e0-407c-4ffe-ab6e-f6a3e0550e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428932, 1)\n",
      "In [179] used 0.0078 MiB RAM in 0.25s, peaked 0.00 MiB above current, total RAM usage 2033.65 MiB\n"
     ]
    }
   ],
   "source": [
    "df_train_all = pd.read_csv(TRAIN_CSV)\n",
    "df_train_all = df_train_all.set_index(['stock_id', 'time_id'])\n",
    "print(df_train_all.shape)\n",
    "#rows_for_stock_id_0 = df_train_all.query('stock_id == 0').shape[0]\n",
    "#rows_for_stock_id_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b852854c-236e-453e-9ae6-d598cf6d5652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2c] 428,932x1, 0 nulls, is_view True, is_single_block True, is_consolidated True\n",
      "In [180] used 0.0000 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 2033.65 MiB\n"
     ]
    }
   ],
   "source": [
    "def show_details(df):\n",
    "    try:\n",
    "        nbr_index_levels = len(df.index.levels)\n",
    "    except AttributeError:\n",
    "        nbr_index_levels = 1\n",
    "    nbr_nulls = df.isnull().sum().sum()\n",
    "    #nulls_msg = \"Has no nulls\"\n",
    "    #if nbr_nulls==0:\n",
    "    nulls_msg = f\"{nbr_nulls} nulls\"\n",
    "    is_view_msg = f'is_view {df_train_all._data.is_view}'\n",
    "    is_single_block_msg = f'is_single_block {df_train_all._data.is_single_block}'\n",
    "    is_consolidated_msg = f'is_consolidated {df_train_all._data.is_consolidated()}'    \n",
    "    print(f'[{nbr_index_levels}c] {df.shape[0]:,}x{df.shape[1]:,}, {nulls_msg}, {is_view_msg}, {is_single_block_msg}, {is_consolidated_msg}')\n",
    "\n",
    "show_details(df_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "350685ba-87de-4df2-ae72-a8bc0105de27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 3,830 time ids\n",
      "Taking 2,872 for train and 958 for test\n",
      "Example time ids for training, min first: [5, 11, 16, 31, 62]\n",
      "In [181] used 0.0000 MiB RAM in 0.13s, peaked 0.00 MiB above current, total RAM usage 2033.65 MiB\n"
     ]
    }
   ],
   "source": [
    "all_time_ids = df_train_all.reset_index().time_id.unique()\n",
    "#np.random.shuffle(all_time_ids) # shuffle the time_ids\n",
    "rng.shuffle(all_time_ids)\n",
    "print(f\"We have {len(all_time_ids):,} time ids\")\n",
    "time_ids_train, time_ids_test = make_unique_time_ids(all_time_ids, test_size=TEST_SIZE)\n",
    "assert len(time_ids_train) + len(time_ids_test) == len(all_time_ids)\n",
    "assert len(time_ids_train.intersection(time_ids_test)) == 0, \"Expecting no overlap between train and test time ids\"\n",
    "print(f\"Example time ids for training, min first: {sorted(list(time_ids_train))[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "079f3c35-eda1-43c1-bcc5-6c9d60ff5ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ask_size1_nunique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>5</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ask_size1_nunique\n",
       "stock_id time_id                   \n",
       "0        5                       67\n",
       "         11                      26\n",
       "         16                      22\n",
       "         31                      30\n",
       "         62                      54"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [182] used 110.0391 MiB RAM in 0.42s, peaked 0.00 MiB above current, total RAM usage 2143.69 MiB\n"
     ]
    }
   ],
   "source": [
    "# make feature columns\n",
    "def make_features_stats(df_book, agg_type, cols):\n",
    "    features_var1 = df_book.groupby(['stock_id', 'time_id'])[cols].agg(agg_type)\n",
    "    #print(type(features_var1))\n",
    "    if isinstance(features_var1, pd.Series):\n",
    "        # .size yields a series not a df\n",
    "        #features_var1.name = str(agg_type)\n",
    "        features_var1 = pd.DataFrame(features_var1, columns=[agg_type])\n",
    "        #pass\n",
    "    else:\n",
    "        features_var1_col_names = [f\"{col}_{agg_type}\" for col in cols]\n",
    "        features_var1.columns = features_var1_col_names\n",
    "    return features_var1\n",
    "\n",
    "if True: # lightweight tests\n",
    "    df_book_train_stock_XX = pd.read_parquet(os.path.join(ROOT, f\"book_train.parquet/stock_id=0\"))\n",
    "    df_book_train_stock_XX[\"stock_id\"] = 0\n",
    "    df_book_train_stock_XX = df_book_train_stock_XX.set_index(['stock_id', 'time_id'])\n",
    "    display(make_features_stats(df_book_train_stock_XX, 'nunique', ['ask_size1']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b3bfc334-1eb5-4323-bd2c-69cb5691a8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [183] used 0.0000 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 2143.69 MiB\n"
     ]
    }
   ],
   "source": [
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff()\n",
    "\n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "faf1a31f-30c3-4ada-a2be-56d5b18f5331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.832396974191326\n",
      "In [184] used 0.0078 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 2143.70 MiB\n"
     ]
    }
   ],
   "source": [
    "def _realized_volatility_weighted_sub(ser, weights):\n",
    "    ser_weighted = ser * weights\n",
    "    return np.sqrt(np.sum(ser_weighted**2))\n",
    "\n",
    "def realized_volatility_weighted(ser, weights_type):\n",
    "    \"\"\"Weighted volatility\"\"\"\n",
    "    # as a numpy array\n",
    "    # we drop from 12us to 3us by adding @njit to the _sub function\n",
    "    # we can't make _sub a closure, it loses all compilation benefits\n",
    "    # and we can't add njit(cache=True) in Jupyter as it can't\n",
    "    # find a cache location    \n",
    "    # as a Series we have 5us and 15us w/wo @njit respectively\n",
    "    if isinstance(ser, pd.Series):\n",
    "        ser = ser.to_numpy()\n",
    "    nbr_items = ser.shape[0]\n",
    "    if weights_type == 'uniform':\n",
    "        weights = np.ones(nbr_items)\n",
    "    elif weights_type == 'linear':\n",
    "        weights = np.linspace(0.1, 1, nbr_items) # linear increasing weight\n",
    "    elif weights_type == 'half0half1':\n",
    "        half_way = int(ser.shape[0] / 2)\n",
    "        weights = np.concatenate((np.zeros(half_way), np.ones(ser.shape[0] - half_way))) # 0s then 1s weight\n",
    "    elif weights_type == 'geom':\n",
    "        weights = np.geomspace(0.01, 1, nbr_items) # geometric increase\n",
    "    #assert isinstance(weights_type, str) == False, f\"Must not be a string like '{weights}' at this point\"\n",
    "    return _realized_volatility_weighted_sub(ser, weights)\n",
    "\n",
    "if True:\n",
    "    series_log_return = pd.Series(np.linspace(0, 10, 6))\n",
    "    print(realized_volatility_weighted(series_log_return, weights_type=\"uniform\"))\n",
    "\n",
    "    #%timeit realized_volatility_weighted(series_log_return, weights_type=\"uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4d7cc64c-600a-4769-af60-95df012f728d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [185] used 0.0156 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 2143.71 MiB\n"
     ]
    }
   ],
   "source": [
    "def realized_volatility_weightedOLD(ser, weights=None):\n",
    "    \"\"\"Weighted volatility\"\"\"\n",
    "    #ser = series_log_return\n",
    "    if weights == \"uniform\":\n",
    "        weight_arr = np.ones(ser.shape[0])\n",
    "    elif weights == 'linear':\n",
    "        weight_arr = np.linspace(0.1, 1, ser.shape[0]) # linear increasing weight\n",
    "    #assert weights is not None, \"Must have set a valid description before here\"\n",
    "    #ser_weighted = ser * weights\n",
    "    return np.sqrt(np.sum((ser * weight_arr)**2))\n",
    "\n",
    "if False:\n",
    "    # example usage\n",
    "    series_log_return = np.linspace(0, 10, 6)\n",
    "    weights = np.linspace(0.1, 1, series_log_return.shape[0]) # linear increasing weight\n",
    "\n",
    "    half_way = int(series_log_return.shape[0] / 2)\n",
    "    weights = np.concatenate((np.zeros(half_way), np.ones(series_log_return.shape[0] - half_way))) # 0s then 1s weight\n",
    "\n",
    "    weights = np.ones(series_log_return.shape[0]) # use all items equally\n",
    "    assert weights.shape[0] == series_log_return.shape[0]\n",
    "    realized_volatility_weighted(series_log_return, 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9d530b07-9a93-4b78-bcb6-7cf4a4fbcbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [186] used 0.1055 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 2143.82 MiB\n"
     ]
    }
   ],
   "source": [
    "def make_wap(df_book_data, num=1, wap_colname=\"wap\"):\n",
    "    \"\"\"Modifies df_book_data\"\"\"\n",
    "    assert num==1 or num==2\n",
    "    wap_numerator = (df_book_data[f'bid_price{num}'] * df_book_data[f'ask_size{num}'] +\n",
    "                                     df_book_data[f'ask_price{num}'] * df_book_data[f'bid_size{num}'])\n",
    "    wap_denominator = df_book_data[f'bid_size{num}'] + df_book_data[f'ask_size{num}']\n",
    "    df_book_data[wap_colname] = wap_numerator / wap_denominator\n",
    "\n",
    "@memory.cache\n",
    "def make_realized_volatility(df_book_data, log_return_name='log_return', wap_colname='wap', weights=None):\n",
    "    \"\"\"Consume wap column\"\"\"\n",
    "    df_book_data[log_return_name] = df_book_data.groupby(['stock_id', 'time_id'])[wap_colname].apply(log_return)\n",
    "    df_book_data = df_book_data[~df_book_data[log_return_name].isnull()]\n",
    "    df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['stock_id', 'time_id'])[log_return_name].agg(realized_volatility_weighted, weights))\n",
    "    return df_realized_vol_per_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9078f53d-d206-4977-8ea6-e450ca8e3e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [187] used 99.1680 MiB RAM in 0.28s, peaked 0.00 MiB above current, total RAM usage 2242.99 MiB\n"
     ]
    }
   ],
   "source": [
    "if True: # lightweight tests\n",
    "    df_book_train_stock_XX = pd.read_parquet(os.path.join(ROOT, f\"book_train.parquet/stock_id=0\"))\n",
    "    df_book_train_stock_XX[\"stock_id\"] = 0\n",
    "    df_book_train_stock_XX = df_book_train_stock_XX.set_index(['stock_id', 'time_id'])\n",
    "    make_wap(df_book_train_stock_XX, 2) # adds 'wap' column\n",
    "    #df_realized_vol_per_stockXX = make_realized_volatility(df_book_train_stock_XX, log_return_name=\"log_return2\", weights='linear')\n",
    "    #display(df_realized_vol_per_stockXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "730f2f79-1acc-4f3e-bb36-c4990ac74cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>bid_price1_var</th>\n",
       "      <th>ask_price1_var</th>\n",
       "      <th>bid_price2_var</th>\n",
       "      <th>ask_price2_var</th>\n",
       "      <th>bid_size1_var</th>\n",
       "      <th>ask_size1_var</th>\n",
       "      <th>bid_size2_var</th>\n",
       "      <th>ask_size2_var</th>\n",
       "      <th>bid_price1_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>bid_size1_nunique</th>\n",
       "      <th>ask_size1_nunique</th>\n",
       "      <th>bid_size2_nunique</th>\n",
       "      <th>ask_size2_nunique</th>\n",
       "      <th>log_return1_uniform</th>\n",
       "      <th>log_return2_uniform</th>\n",
       "      <th>log_return1_linear</th>\n",
       "      <th>log_return2_linear</th>\n",
       "      <th>log_return1_half0half1</th>\n",
       "      <th>log_return2_half0half1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">0</th>\n",
       "      <th>5</th>\n",
       "      <td>0.004136</td>\n",
       "      <td>3.557702e-07</td>\n",
       "      <td>3.609267e-07</td>\n",
       "      <td>3.278967e-07</td>\n",
       "      <td>3.649655e-07</td>\n",
       "      <td>6592.215309</td>\n",
       "      <td>4338.669743</td>\n",
       "      <td>7348.756507</td>\n",
       "      <td>5184.163572</td>\n",
       "      <td>1.003314</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>67</td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.004940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001445</td>\n",
       "      <td>8.048454e-08</td>\n",
       "      <td>4.782809e-08</td>\n",
       "      <td>5.987733e-08</td>\n",
       "      <td>4.715270e-08</td>\n",
       "      <td>15492.325402</td>\n",
       "      <td>9691.320578</td>\n",
       "      <td>8465.001985</td>\n",
       "      <td>7875.531633</td>\n",
       "      <td>1.000011</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>44</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.001981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002168</td>\n",
       "      <td>5.057495e-07</td>\n",
       "      <td>6.204843e-07</td>\n",
       "      <td>5.307066e-07</td>\n",
       "      <td>6.152997e-07</td>\n",
       "      <td>4978.115912</td>\n",
       "      <td>9259.747269</td>\n",
       "      <td>5674.860251</td>\n",
       "      <td>4586.227415</td>\n",
       "      <td>0.999204</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>21</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.003759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.002195</td>\n",
       "      <td>4.746649e-07</td>\n",
       "      <td>3.223060e-07</td>\n",
       "      <td>5.349445e-07</td>\n",
       "      <td>3.222207e-07</td>\n",
       "      <td>8093.880602</td>\n",
       "      <td>10996.043697</td>\n",
       "      <td>5778.103922</td>\n",
       "      <td>6483.167437</td>\n",
       "      <td>0.998445</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.002868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.001747</td>\n",
       "      <td>4.740689e-08</td>\n",
       "      <td>3.653909e-08</td>\n",
       "      <td>5.247379e-08</td>\n",
       "      <td>3.838027e-08</td>\n",
       "      <td>9499.414513</td>\n",
       "      <td>9603.210909</td>\n",
       "      <td>7059.243117</td>\n",
       "      <td>4527.422208</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>54</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.002106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32751</th>\n",
       "      <td>0.002611</td>\n",
       "      <td>3.989057e-07</td>\n",
       "      <td>5.059281e-07</td>\n",
       "      <td>3.846314e-07</td>\n",
       "      <td>4.818288e-07</td>\n",
       "      <td>9490.991605</td>\n",
       "      <td>10394.996610</td>\n",
       "      <td>4828.041246</td>\n",
       "      <td>9333.874374</td>\n",
       "      <td>0.997639</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>63</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.002506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32753</th>\n",
       "      <td>0.001190</td>\n",
       "      <td>1.837252e-07</td>\n",
       "      <td>2.433933e-07</td>\n",
       "      <td>2.033434e-07</td>\n",
       "      <td>2.618266e-07</td>\n",
       "      <td>28270.493701</td>\n",
       "      <td>20407.077646</td>\n",
       "      <td>15863.063249</td>\n",
       "      <td>10575.195643</td>\n",
       "      <td>1.000141</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>59</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.002265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32758</th>\n",
       "      <td>0.004264</td>\n",
       "      <td>5.668076e-07</td>\n",
       "      <td>4.536424e-07</td>\n",
       "      <td>6.043470e-07</td>\n",
       "      <td>4.448702e-07</td>\n",
       "      <td>6587.428917</td>\n",
       "      <td>7851.263511</td>\n",
       "      <td>2219.748436</td>\n",
       "      <td>5428.886648</td>\n",
       "      <td>0.999334</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.002473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32763</th>\n",
       "      <td>0.004352</td>\n",
       "      <td>1.058614e-07</td>\n",
       "      <td>1.051107e-07</td>\n",
       "      <td>1.070506e-07</td>\n",
       "      <td>1.431541e-07</td>\n",
       "      <td>7244.247983</td>\n",
       "      <td>6607.922889</td>\n",
       "      <td>8062.183603</td>\n",
       "      <td>5552.617083</td>\n",
       "      <td>1.002087</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.003813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32767</th>\n",
       "      <td>0.001084</td>\n",
       "      <td>5.710588e-07</td>\n",
       "      <td>5.752923e-07</td>\n",
       "      <td>6.009845e-07</td>\n",
       "      <td>5.970896e-07</td>\n",
       "      <td>9402.179206</td>\n",
       "      <td>10214.490359</td>\n",
       "      <td>12848.133608</td>\n",
       "      <td>6756.769515</td>\n",
       "      <td>0.998886</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.001517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3830 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    target  bid_price1_var  ask_price1_var  bid_price2_var  \\\n",
       "stock_id time_id                                                             \n",
       "0        5        0.004136    3.557702e-07    3.609267e-07    3.278967e-07   \n",
       "         11       0.001445    8.048454e-08    4.782809e-08    5.987733e-08   \n",
       "         16       0.002168    5.057495e-07    6.204843e-07    5.307066e-07   \n",
       "         31       0.002195    4.746649e-07    3.223060e-07    5.349445e-07   \n",
       "         62       0.001747    4.740689e-08    3.653909e-08    5.247379e-08   \n",
       "...                    ...             ...             ...             ...   \n",
       "         32751    0.002611    3.989057e-07    5.059281e-07    3.846314e-07   \n",
       "         32753    0.001190    1.837252e-07    2.433933e-07    2.033434e-07   \n",
       "         32758    0.004264    5.668076e-07    4.536424e-07    6.043470e-07   \n",
       "         32763    0.004352    1.058614e-07    1.051107e-07    1.070506e-07   \n",
       "         32767    0.001084    5.710588e-07    5.752923e-07    6.009845e-07   \n",
       "\n",
       "                  ask_price2_var  bid_size1_var  ask_size1_var  bid_size2_var  \\\n",
       "stock_id time_id                                                                \n",
       "0        5          3.649655e-07    6592.215309    4338.669743    7348.756507   \n",
       "         11         4.715270e-08   15492.325402    9691.320578    8465.001985   \n",
       "         16         6.152997e-07    4978.115912    9259.747269    5674.860251   \n",
       "         31         3.222207e-07    8093.880602   10996.043697    5778.103922   \n",
       "         62         3.838027e-08    9499.414513    9603.210909    7059.243117   \n",
       "...                          ...            ...            ...            ...   \n",
       "         32751      4.818288e-07    9490.991605   10394.996610    4828.041246   \n",
       "         32753      2.618266e-07   28270.493701   20407.077646   15863.063249   \n",
       "         32758      4.448702e-07    6587.428917    7851.263511    2219.748436   \n",
       "         32763      1.431541e-07    7244.247983    6607.922889    8062.183603   \n",
       "         32767      5.970896e-07    9402.179206   10214.490359   12848.133608   \n",
       "\n",
       "                  ask_size2_var  bid_price1_mean  ...  bid_size1_nunique  \\\n",
       "stock_id time_id                                  ...                      \n",
       "0        5          5184.163572         1.003314  ...                 44   \n",
       "         11         7875.531633         1.000011  ...                 58   \n",
       "         16         4586.227415         0.999204  ...                 43   \n",
       "         31         6483.167437         0.998445  ...                 24   \n",
       "         62         4527.422208         0.999407  ...                 23   \n",
       "...                         ...              ...  ...                ...   \n",
       "         32751      9333.874374         0.997639  ...                 54   \n",
       "         32753     10575.195643         1.000141  ...                 36   \n",
       "         32758      5428.886648         0.999334  ...                 37   \n",
       "         32763      5552.617083         1.002087  ...                 39   \n",
       "         32767      6756.769515         0.998886  ...                 23   \n",
       "\n",
       "                  ask_size1_nunique  bid_size2_nunique  ask_size2_nunique  \\\n",
       "stock_id time_id                                                            \n",
       "0        5                       67                 32                 46   \n",
       "         11                      26                 26                 44   \n",
       "         16                      22                 43                 21   \n",
       "         31                      30                 24                 34   \n",
       "         62                      54                 26                 43   \n",
       "...                             ...                ...                ...   \n",
       "         32751                   63                 31                 57   \n",
       "         32753                   59                 39                 40   \n",
       "         32758                   42                 35                 20   \n",
       "         32763                   42                 27                 41   \n",
       "         32767                   50                 22                 35   \n",
       "\n",
       "                  log_return1_uniform  log_return2_uniform  \\\n",
       "stock_id time_id                                             \n",
       "0        5                   0.004499             0.006999   \n",
       "         11                  0.001204             0.002476   \n",
       "         16                  0.002369             0.004801   \n",
       "         31                  0.002574             0.003637   \n",
       "         62                  0.001894             0.003257   \n",
       "...                               ...                  ...   \n",
       "         32751               0.002579             0.003821   \n",
       "         32753               0.002206             0.002847   \n",
       "         32758               0.002913             0.003266   \n",
       "         32763               0.003046             0.005105   \n",
       "         32767               0.001901             0.002541   \n",
       "\n",
       "                  log_return1_linear  log_return2_linear  \\\n",
       "stock_id time_id                                           \n",
       "0        5                  0.002517            0.004500   \n",
       "         11                 0.000904            0.001749   \n",
       "         16                 0.001504            0.003284   \n",
       "         31                 0.001665            0.002465   \n",
       "         62                 0.001402            0.001806   \n",
       "...                              ...                 ...   \n",
       "         32751              0.001525            0.002343   \n",
       "         32753              0.001252            0.001905   \n",
       "         32758              0.001542            0.002118   \n",
       "         32763              0.001840            0.003160   \n",
       "         32767              0.001330            0.001316   \n",
       "\n",
       "                  log_return1_half0half1  log_return2_half0half1  \n",
       "stock_id time_id                                                  \n",
       "0        5                      0.003051                0.004940  \n",
       "         11                     0.000976                0.001981  \n",
       "         16                     0.001898                0.003759  \n",
       "         31                     0.001840                0.002868  \n",
       "         62                     0.001519                0.002106  \n",
       "...                                  ...                     ...  \n",
       "         32751                  0.001617                0.002506  \n",
       "         32753                  0.001487                0.002265  \n",
       "         32758                  0.001600                0.002473  \n",
       "         32763                  0.002004                0.003813  \n",
       "         32767                  0.001507                0.001517  \n",
       "\n",
       "[3830 rows x 48 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [210] used -71.6836 MiB RAM in 12.49s, peaked 173.16 MiB above current, total RAM usage 2250.65 MiB\n"
     ]
    }
   ],
   "source": [
    "@memory.cache\n",
    "def load_data_build_features(stock_id, ROOT, filename, cols, df_target):\n",
    "    # filename e.g. book_train.parquet\n",
    "    assert isinstance(stock_id, int)\n",
    "    df_book_train_stock_X = pd.read_parquet(\n",
    "        os.path.join(ROOT, f\"{filename}/stock_id={stock_id}\")\n",
    "    )\n",
    "    df_book_train_stock_X[\"stock_id\"] = stock_id\n",
    "    df_book_train_stock_X = df_book_train_stock_X.set_index(['stock_id', 'time_id'])\n",
    "    #assert df_book_train_stock_X.shape[0] > rows_for_stock_id_0, (df_book_train_stock_X.shape[0], rows_for_stock_id_0)\n",
    "    \n",
    "    #df_book_train_stock_X_gt500 = df_book_train_stock_X.query(\"seconds_in_bucket>500\").copy()\n",
    "    #df_realized_vol_per_stock_short500 = add_wap_make_realized_volatility(df_book_train_stock_X_gt500, log_return_name='log_return_gt500sec')\n",
    "    #df_book_train_stock_X_gt300 = df_book_train_stock_X.query(\"seconds_in_bucket>300\").copy()\n",
    "    #df_realized_vol_per_stock_short300 = add_wap_make_realized_volatility(df_book_train_stock_X_gt300, log_return_name='log_return_gt300sec')\n",
    "    make_wap(df_book_train_stock_X, 2, \"wap2\") \n",
    "    df_realized_vol_per_stock_wap2_uniform = make_realized_volatility(df_book_train_stock_X, log_return_name=\"log_return2_uniform\", wap_colname=\"wap2\", weights='uniform')    \n",
    "    df_realized_vol_per_stock_wap2_linear = make_realized_volatility(df_book_train_stock_X, log_return_name=\"log_return2_linear\", wap_colname=\"wap2\", weights='linear')\n",
    "    df_realized_vol_per_stock_wap2_half0half1 = make_realized_volatility(df_book_train_stock_X, log_return_name=\"log_return2_half0half1\", wap_colname=\"wap2\", weights='half0half1')\n",
    "    make_wap(df_book_train_stock_X, 1, \"wap\") # adds 'wap' column\n",
    "    df_realized_vol_per_stock_wap1_uniform = make_realized_volatility(df_book_train_stock_X, log_return_name=\"log_return1_uniform\", weights='uniform')\n",
    "    df_realized_vol_per_stock_wap1_linear = make_realized_volatility(df_book_train_stock_X, log_return_name=\"log_return1_linear\", weights='linear')\n",
    "    df_realized_vol_per_stock_wap1_half0half1 = make_realized_volatility(df_book_train_stock_X, log_return_name=\"log_return1_half0half1\", weights='half0half1')\n",
    "    \n",
    "    features_var1 = make_features_stats(df_book_train_stock_X, 'var', cols)\n",
    "    features_mean1 = make_features_stats(df_book_train_stock_X, 'mean', cols)\n",
    "    features_size1 = make_features_stats(df_book_train_stock_X, 'size', cols)\n",
    "    features_min1 = make_features_stats(df_book_train_stock_X, 'min', cols)\n",
    "    features_max1 = make_features_stats(df_book_train_stock_X, 'max', cols)\n",
    "    features_nunique1 = make_features_stats(df_book_train_stock_X, 'nunique', cols)\n",
    "    \n",
    "    df_train_stock_X = df_target.query('stock_id == @stock_id')\n",
    "    to_merge = [df_train_stock_X, \n",
    "                features_var1, features_mean1, features_size1, \n",
    "                features_min1, features_max1, features_nunique1,\n",
    "                df_realized_vol_per_stock_wap1_uniform,\n",
    "                df_realized_vol_per_stock_wap2_uniform,\n",
    "                df_realized_vol_per_stock_wap1_linear,\n",
    "                df_realized_vol_per_stock_wap2_linear,\n",
    "                df_realized_vol_per_stock_wap1_half0half1,\n",
    "                df_realized_vol_per_stock_wap2_half0half1]\n",
    "    row_lengths = [df.shape[0] for df in to_merge]\n",
    "    assert len(set(row_lengths)) == 1, row_lengths # should all be same length\n",
    "    train_merged = pd.concat(to_merge, axis=1)\n",
    "    \n",
    "    if 'target' in train_merged.columns:\n",
    "        # no need to check for duplication on the test set\n",
    "        features = train_merged.drop(columns='target').columns\n",
    "        #print(features)\n",
    "        assert len(set(features)) == len(features), f\"Feature duplication! {len(set(features))} vs {len(features)}\"\n",
    "\n",
    "    return train_merged\n",
    "\n",
    "#if 'memory' in dir():\n",
    "#    # only setup local cache if we're running locally in development\n",
    "#    load_data_build_features = memory.cache(load_data_build_features)\n",
    "    \n",
    "cols = ['bid_price1', 'ask_price1', 'bid_price2', 'ask_price2',] \n",
    "cols += ['bid_size1', 'ask_size1', 'bid_size2', 'ask_size2']\n",
    "\n",
    "if True:    \n",
    "    # test...\n",
    "    train_mergedXX = load_data_build_features(0, ROOT, 'book_train.parquet', cols, df_train_all)\n",
    "    display(train_mergedXX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bce31de7-961b-440f-9eee-824c3b4e1aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating over 112 stocks:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1954s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 112 out of 112 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [189] used -192.8281 MiB RAM in 2.27s, peaked 168.30 MiB above current, total RAM usage 2050.09 MiB\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "print(f'Iterating over {len(stock_ids)} stocks:')\n",
    "\n",
    "all_train_merged = Parallel(n_jobs=-1, verbose=10)(delayed(load_data_build_features)(stock_id, ROOT, 'book_train.parquet', cols, df_train_all) for stock_id in stock_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e41a8bbd-ea61-4121-a0f7-a303cb0940d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2c] 428,932x48, 0 nulls, is_view True, is_single_block True, is_consolidated True\n",
      "In [190] used -10.8086 MiB RAM in 0.31s, peaked 39.49 MiB above current, total RAM usage 2039.29 MiB\n"
     ]
    }
   ],
   "source": [
    "# join all the partial results back together\n",
    "train_merged = pd.concat(all_train_merged)\n",
    "show_details(train_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "47e53e2a-2e5f-48e3-9ada-0ab519af8bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>bid_price1_var</th>\n",
       "      <th>ask_price1_var</th>\n",
       "      <th>bid_price2_var</th>\n",
       "      <th>ask_price2_var</th>\n",
       "      <th>bid_size1_var</th>\n",
       "      <th>ask_size1_var</th>\n",
       "      <th>bid_size2_var</th>\n",
       "      <th>ask_size2_var</th>\n",
       "      <th>bid_price1_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>bid_size1_nunique</th>\n",
       "      <th>ask_size1_nunique</th>\n",
       "      <th>bid_size2_nunique</th>\n",
       "      <th>ask_size2_nunique</th>\n",
       "      <th>log_return1_uniform</th>\n",
       "      <th>log_return2_uniform</th>\n",
       "      <th>log_return1_linear</th>\n",
       "      <th>log_return2_linear</th>\n",
       "      <th>log_return1_half0half1</th>\n",
       "      <th>log_return2_half0half1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">59</th>\n",
       "      <th>5</th>\n",
       "      <td>0.004072</td>\n",
       "      <td>1.539389e-07</td>\n",
       "      <td>1.544176e-07</td>\n",
       "      <td>1.349132e-07</td>\n",
       "      <td>1.465483e-07</td>\n",
       "      <td>11855.387055</td>\n",
       "      <td>6892.936853</td>\n",
       "      <td>4510.521751</td>\n",
       "      <td>5765.414169</td>\n",
       "      <td>1.000904</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>91</td>\n",
       "      <td>42</td>\n",
       "      <td>63</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.002576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001489</td>\n",
       "      <td>3.412355e-07</td>\n",
       "      <td>4.039657e-07</td>\n",
       "      <td>3.298110e-07</td>\n",
       "      <td>4.177058e-07</td>\n",
       "      <td>22438.854139</td>\n",
       "      <td>32757.977261</td>\n",
       "      <td>35927.916710</td>\n",
       "      <td>16786.511136</td>\n",
       "      <td>1.000577</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>58</td>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.003312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002563</td>\n",
       "      <td>5.515992e-07</td>\n",
       "      <td>5.405377e-07</td>\n",
       "      <td>5.369475e-07</td>\n",
       "      <td>5.369036e-07</td>\n",
       "      <td>10481.927458</td>\n",
       "      <td>12315.572839</td>\n",
       "      <td>6729.414078</td>\n",
       "      <td>6091.421681</td>\n",
       "      <td>0.999024</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>69</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>0.002423</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.002353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.002323</td>\n",
       "      <td>4.119776e-08</td>\n",
       "      <td>9.782350e-08</td>\n",
       "      <td>5.722407e-08</td>\n",
       "      <td>9.959539e-08</td>\n",
       "      <td>6566.613651</td>\n",
       "      <td>7043.215464</td>\n",
       "      <td>5424.648518</td>\n",
       "      <td>8061.372315</td>\n",
       "      <td>1.000029</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>0.003381</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.002446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.002398</td>\n",
       "      <td>2.799989e-07</td>\n",
       "      <td>3.039634e-07</td>\n",
       "      <td>2.906845e-07</td>\n",
       "      <td>2.920635e-07</td>\n",
       "      <td>16026.168376</td>\n",
       "      <td>12337.165290</td>\n",
       "      <td>9310.249809</td>\n",
       "      <td>7555.724324</td>\n",
       "      <td>0.997103</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>19</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.002025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    target  bid_price1_var  ask_price1_var  bid_price2_var  \\\n",
       "stock_id time_id                                                             \n",
       "59       5        0.004072    1.539389e-07    1.544176e-07    1.349132e-07   \n",
       "         11       0.001489    3.412355e-07    4.039657e-07    3.298110e-07   \n",
       "         16       0.002563    5.515992e-07    5.405377e-07    5.369475e-07   \n",
       "         31       0.002323    4.119776e-08    9.782350e-08    5.722407e-08   \n",
       "         62       0.002398    2.799989e-07    3.039634e-07    2.906845e-07   \n",
       "\n",
       "                  ask_price2_var  bid_size1_var  ask_size1_var  bid_size2_var  \\\n",
       "stock_id time_id                                                                \n",
       "59       5          1.465483e-07   11855.387055    6892.936853    4510.521751   \n",
       "         11         4.177058e-07   22438.854139   32757.977261   35927.916710   \n",
       "         16         5.369036e-07   10481.927458   12315.572839    6729.414078   \n",
       "         31         9.959539e-08    6566.613651    7043.215464    5424.648518   \n",
       "         62         2.920635e-07   16026.168376   12337.165290    9310.249809   \n",
       "\n",
       "                  ask_size2_var  bid_price1_mean  ...  bid_size1_nunique  \\\n",
       "stock_id time_id                                  ...                      \n",
       "59       5          5765.414169         1.000904  ...                 55   \n",
       "         11        16786.511136         1.000577  ...                 66   \n",
       "         16         6091.421681         0.999024  ...                 18   \n",
       "         31         8061.372315         1.000029  ...                 40   \n",
       "         62         7555.724324         0.997103  ...                 59   \n",
       "\n",
       "                  ask_size1_nunique  bid_size2_nunique  ask_size2_nunique  \\\n",
       "stock_id time_id                                                            \n",
       "59       5                       91                 42                 63   \n",
       "         11                      58                 34                 39   \n",
       "         16                      69                 19                 39   \n",
       "         31                      31                 34                 35   \n",
       "         62                      38                 43                 19   \n",
       "\n",
       "                  log_return1_uniform  log_return2_uniform  \\\n",
       "stock_id time_id                                             \n",
       "59       5                   0.002861             0.003991   \n",
       "         11                  0.002905             0.004020   \n",
       "         16                  0.002423             0.003329   \n",
       "         31                  0.002573             0.003381   \n",
       "         62                  0.002345             0.003060   \n",
       "\n",
       "                  log_return1_linear  log_return2_linear  \\\n",
       "stock_id time_id                                           \n",
       "59       5                  0.001431            0.002188   \n",
       "         11                 0.001629            0.002768   \n",
       "         16                 0.001488            0.002022   \n",
       "         31                 0.001407            0.002040   \n",
       "         62                 0.001263            0.001727   \n",
       "\n",
       "                  log_return1_half0half1  log_return2_half0half1  \n",
       "stock_id time_id                                                  \n",
       "59       5                      0.001584                0.002576  \n",
       "         11                     0.001959                0.003312  \n",
       "         16                     0.001859                0.002353  \n",
       "         31                     0.001574                0.002446  \n",
       "         62                     0.001524                0.002025  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [191] used 0.0000 MiB RAM in 0.12s, peaked 0.00 MiB above current, total RAM usage 2039.29 MiB\n"
     ]
    }
   ],
   "source": [
    "train_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0c8c58d2-9e7e-41a7-8ecb-035762d33e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bid_price1_var', 'ask_price1_var', 'bid_price2_var', 'ask_price2_var',\n",
      "       'bid_size1_var', 'ask_size1_var', 'bid_size2_var', 'ask_size2_var',\n",
      "       'bid_price1_mean', 'ask_price1_mean', 'bid_price2_mean',\n",
      "       'ask_price2_mean', 'bid_size1_mean', 'ask_size1_mean', 'bid_size2_mean',\n",
      "       'ask_size2_mean', 'size', 'bid_price1_min', 'ask_price1_min',\n",
      "       'bid_price2_min', 'ask_price2_min', 'bid_size1_min', 'ask_size1_min',\n",
      "       'bid_size2_min', 'ask_size2_min', 'bid_price1_max', 'ask_price1_max',\n",
      "       'bid_price2_max', 'ask_price2_max', 'bid_size1_max', 'ask_size1_max',\n",
      "       'bid_size2_max', 'ask_size2_max', 'bid_price1_nunique',\n",
      "       'ask_price1_nunique', 'bid_price2_nunique', 'ask_price2_nunique',\n",
      "       'bid_size1_nunique', 'ask_size1_nunique', 'bid_size2_nunique',\n",
      "       'ask_size2_nunique', 'log_return1_uniform', 'log_return2_uniform',\n",
      "       'log_return1_linear', 'log_return2_linear', 'log_return1_half0half1',\n",
      "       'log_return2_half0half1'],\n",
      "      dtype='object')\n",
      "In [192] used 137.4570 MiB RAM in 0.21s, peaked 0.00 MiB above current, total RAM usage 2176.74 MiB\n"
     ]
    }
   ],
   "source": [
    "features = train_merged.drop(columns='target').columns\n",
    "print(features)\n",
    "assert len(set(features)) == len(features), f\"{len(set(features))} vs {len(features)} features, we should not have any duplicates\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa604e88-0b6f-438a-9143-9bce7289a0a1",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "38c715f1-d4f9-4eb3-b0f1-6942f11341e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((321646, 48), (107286, 48), (321646,), (107286,))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [193] used 179.1484 MiB RAM in 0.46s, peaked 84.89 MiB above current, total RAM usage 2355.89 MiB\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(df, target_col, time_ids_train, time_ids_test):\n",
    "    X_train = df.query('time_id in @time_ids_train').drop(columns=[target_col, 'time_id'])\n",
    "    X_test = df.query('time_id in @time_ids_test').drop(columns=[target_col, 'time_id'])\n",
    "    y_train = df.query('time_id in @time_ids_train')[target_col]\n",
    "    y_test = df.query('time_id in @time_ids_test')[target_col]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "feature_cols = list(features) + ['stock_id']\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_merged.reset_index()[feature_cols+['time_id', 'target']], 'target', time_ids_train, time_ids_test)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1eeb0826-a793-495e-9096-2ccd215f32e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bid_price1_var</th>\n",
       "      <th>ask_price1_var</th>\n",
       "      <th>bid_price2_var</th>\n",
       "      <th>ask_price2_var</th>\n",
       "      <th>bid_size1_var</th>\n",
       "      <th>ask_size1_var</th>\n",
       "      <th>bid_size2_var</th>\n",
       "      <th>ask_size2_var</th>\n",
       "      <th>bid_price1_mean</th>\n",
       "      <th>ask_price1_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>ask_size1_nunique</th>\n",
       "      <th>bid_size2_nunique</th>\n",
       "      <th>ask_size2_nunique</th>\n",
       "      <th>log_return1_uniform</th>\n",
       "      <th>log_return2_uniform</th>\n",
       "      <th>log_return1_linear</th>\n",
       "      <th>log_return2_linear</th>\n",
       "      <th>log_return1_half0half1</th>\n",
       "      <th>log_return2_half0half1</th>\n",
       "      <th>stock_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.539389e-07</td>\n",
       "      <td>1.544176e-07</td>\n",
       "      <td>1.349132e-07</td>\n",
       "      <td>1.465483e-07</td>\n",
       "      <td>11855.387055</td>\n",
       "      <td>6892.936853</td>\n",
       "      <td>4510.521751</td>\n",
       "      <td>5765.414169</td>\n",
       "      <td>1.000904</td>\n",
       "      <td>1.001389</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>42</td>\n",
       "      <td>63</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.412355e-07</td>\n",
       "      <td>4.039657e-07</td>\n",
       "      <td>3.298110e-07</td>\n",
       "      <td>4.177058e-07</td>\n",
       "      <td>22438.854139</td>\n",
       "      <td>32757.977261</td>\n",
       "      <td>35927.916710</td>\n",
       "      <td>16786.511136</td>\n",
       "      <td>1.000577</td>\n",
       "      <td>1.001177</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.003312</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.515992e-07</td>\n",
       "      <td>5.405377e-07</td>\n",
       "      <td>5.369475e-07</td>\n",
       "      <td>5.369036e-07</td>\n",
       "      <td>10481.927458</td>\n",
       "      <td>12315.572839</td>\n",
       "      <td>6729.414078</td>\n",
       "      <td>6091.421681</td>\n",
       "      <td>0.999024</td>\n",
       "      <td>0.999396</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>0.002423</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bid_price1_var  ask_price1_var  bid_price2_var  ask_price2_var  \\\n",
       "0    1.539389e-07    1.544176e-07    1.349132e-07    1.465483e-07   \n",
       "1    3.412355e-07    4.039657e-07    3.298110e-07    4.177058e-07   \n",
       "2    5.515992e-07    5.405377e-07    5.369475e-07    5.369036e-07   \n",
       "\n",
       "   bid_size1_var  ask_size1_var  bid_size2_var  ask_size2_var  \\\n",
       "0   11855.387055    6892.936853    4510.521751    5765.414169   \n",
       "1   22438.854139   32757.977261   35927.916710   16786.511136   \n",
       "2   10481.927458   12315.572839    6729.414078    6091.421681   \n",
       "\n",
       "   bid_price1_mean  ask_price1_mean  ...  ask_size1_nunique  \\\n",
       "0         1.000904         1.001389  ...                 91   \n",
       "1         1.000577         1.001177  ...                 58   \n",
       "2         0.999024         0.999396  ...                 69   \n",
       "\n",
       "   bid_size2_nunique  ask_size2_nunique  log_return1_uniform  \\\n",
       "0                 42                 63             0.002861   \n",
       "1                 34                 39             0.002905   \n",
       "2                 19                 39             0.002423   \n",
       "\n",
       "   log_return2_uniform  log_return1_linear  log_return2_linear  \\\n",
       "0             0.003991            0.001431            0.002188   \n",
       "1             0.004020            0.001629            0.002768   \n",
       "2             0.003329            0.001488            0.002022   \n",
       "\n",
       "   log_return1_half0half1  log_return2_half0half1  stock_id  \n",
       "0                0.001584                0.002576        59  \n",
       "1                0.001959                0.003312        59  \n",
       "2                0.001859                0.002353        59  \n",
       "\n",
       "[3 rows x 48 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [194] used 0.0000 MiB RAM in 0.14s, peaked 0.00 MiB above current, total RAM usage 2355.89 MiB\n"
     ]
    }
   ],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d7d9c065-3d86-4708-a9fc-06e7438471cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((321646, 48), (107286, 48), (321646,), (107286,))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [195] used 0.0000 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 2355.89 MiB\n"
     ]
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e707413-28fc-4963-8281-f5c6a9d49cd7",
   "metadata": {},
   "source": [
    "# ML on a train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5fee6800-336e-4e6e-84f9-ff513a424f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [196] used -0.0234 MiB RAM in 0.11s, peaked 0.02 MiB above current, total RAM usage 2355.87 MiB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting \n",
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "847d785c-fb6b-4421-a939-9c88f9a5774c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='hist', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [197] used 0.1406 MiB RAM in 4.13s, peaked 117.79 MiB above current, total RAM usage 2356.01 MiB\n"
     ]
    }
   ],
   "source": [
    "#est = LinearRegression()\n",
    "#est = RandomForestRegressor(n_estimators=10, n_jobs=-1, random_state=RANDOM_STATE) # default n_estimators==100\n",
    "#est = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=RANDOM_STATE) # default n_estimators==100\n",
    "#est = GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
    "#est = HistGradientBoostingRegressor(random_state=RANDOM_STATE)\n",
    "\n",
    "# https://xgboost.readthedocs.io/en/latest/python/python_api.html\n",
    "#tree_method='exact' default\n",
    "#est = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "est = xgb.XGBRegressor(tree_method='hist', )\n",
    "\n",
    "#est = LGBMRegressor()\n",
    "\n",
    "est.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ec071e4e-bc2e-4fc0-95c6-2c81bafed376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE_ALL_STOCK_IDS: True\n",
      "112 unique stock ids, test set is 25.0%\n",
      "Features: ['bid_price1_var', 'ask_price1_var', 'bid_price2_var', 'ask_price2_var', 'bid_size1_var', 'ask_size1_var', 'bid_size2_var', 'ask_size2_var', 'bid_price1_mean', 'ask_price1_mean', 'bid_price2_mean', 'ask_price2_mean', 'bid_size1_mean', 'ask_size1_mean', 'bid_size2_mean', 'ask_size2_mean', 'size', 'bid_price1_min', 'ask_price1_min', 'bid_price2_min', 'ask_price2_min', 'bid_size1_min', 'ask_size1_min', 'bid_size2_min', 'ask_size2_min', 'bid_price1_max', 'ask_price1_max', 'bid_price2_max', 'ask_price2_max', 'bid_size1_max', 'ask_size1_max', 'bid_size2_max', 'ask_size2_max', 'bid_price1_nunique', 'ask_price1_nunique', 'bid_price2_nunique', 'ask_price2_nunique', 'bid_size1_nunique', 'ask_size1_nunique', 'bid_size2_nunique', 'ask_size2_nunique', 'log_return1_uniform', 'log_return2_uniform', 'log_return1_linear', 'log_return2_linear', 'log_return1_half0half1', 'log_return2_half0half1', 'stock_id']\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='hist', validate_parameters=1, verbosity=None)\n",
      "rmspe score 0.276, r^2 score 0.816 on 107,286 predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/miniconda3/envs/optiver_volatility/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [198] used 0.0000 MiB RAM in 0.30s, peaked 39.07 MiB above current, total RAM usage 2356.01 MiB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(f\"USE_ALL_STOCK_IDS: {USE_ALL_STOCK_IDS}\")\n",
    "\n",
    "print(f\"{df_train_all.reset_index().stock_id.unique().shape[0]} unique stock ids, test set is {TEST_SIZE*100:0.1f}%\")\n",
    "print(f\"Features:\", feature_cols)\n",
    "print(est)\n",
    "if X_test.shape[0] > 0:\n",
    "    y_pred = est.predict(X_test)\n",
    "    score = r2_score(y_test, y_pred)\n",
    "    rmspe = rmspe_score(y_test, y_pred)\n",
    "    print(f\"rmspe score {rmspe:0.3f}, r^2 score {score:0.3f} on {y_pred.shape[0]:,} predictions\")\n",
    "else:\n",
    "    print('No testing rows in X_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f73ac0af-32ed-4d00-91da-2dc14c1e28c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "TRAIN: [     1      2      4 ... 428927 428928 428930] TEST: [     0      3      6 ... 428926 428929 428931]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/miniconda3/envs/optiver_volatility/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmspe score 0.288, r^2 score 0.805 on 142,904 predictions\n",
      "TRAIN: [     0      1      3 ... 428927 428929 428931] TEST: [     2      5      8 ... 428925 428928 428930]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/miniconda3/envs/optiver_volatility/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmspe score 0.283, r^2 score 0.810 on 143,014 predictions\n",
      "TRAIN: [     0      2      3 ... 428929 428930 428931] TEST: [     1      4      7 ... 428921 428924 428927]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/miniconda3/envs/optiver_volatility/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmspe score 0.287, r^2 score 0.814 on 143,014 predictions\n",
      "CPU times: user 1min 26s, sys: 335 ms, total: 1min 27s\n",
      "Wall time: 12.5 s\n",
      "In [199] used -34.3477 MiB RAM in 12.57s, peaked 157.02 MiB above current, total RAM usage 2321.66 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scores = []\n",
    "if TEST_SIZE > 0:\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html\n",
    "    # note the splits appear to be deterministic, possibly on discovery order\n",
    "    from sklearn.model_selection import GroupKFold\n",
    "    train_merged_no_idx = train_merged.reset_index()\n",
    "    groups = train_merged_no_idx['time_id']\n",
    "    group_kfold = GroupKFold(n_splits=3)\n",
    "    X_all = train_merged_no_idx[feature_cols]\n",
    "    y_all = train_merged_no_idx['target']\n",
    "    print(group_kfold.get_n_splits(X_all, y_all, groups))\n",
    "    for train_index, test_index in group_kfold.split(X_all, y_all, groups):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X_all.loc[train_index], X_all.loc[test_index]\n",
    "        y_train, y_test = y_all.loc[train_index], y_all.loc[test_index]\n",
    "        est.fit(X_train, y_train)\n",
    "        y_pred = est.predict(X_test)\n",
    "        score = r2_score(y_test, y_pred)\n",
    "        rmspe = rmspe_score(y_test, y_pred)\n",
    "        print(f\"rmspe score {rmspe:0.3f}, r^2 score {score:0.3f} on {y_pred.shape[0]:,} predictions\")\n",
    "        scores.append({'r2': score, 'rmspe': rmspe})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a999fbd6-622a-4658-b3a3-9bfa7f7ec7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.804593</td>\n",
       "      <td>0.809950</td>\n",
       "      <td>0.814294</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>0.809612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmspe</th>\n",
       "      <td>0.287959</td>\n",
       "      <td>0.282747</td>\n",
       "      <td>0.286829</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>0.285845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2       std      mean\n",
       "r2     0.804593  0.809950  0.814294  0.004859  0.809612\n",
       "rmspe  0.287959  0.282747  0.286829  0.002742  0.285845"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [209] used -0.0234 MiB RAM in 0.12s, peaked 0.00 MiB above current, total RAM usage 2322.34 MiB\n"
     ]
    }
   ],
   "source": [
    "if len(scores) > 0:\n",
    "    # only show results if we've used cross validation\n",
    "    df_scores = pd.DataFrame(scores).T\n",
    "    folds = df_scores.columns.values\n",
    "    df_scores['std'] = df_scores[folds].std(axis=1)\n",
    "    df_scores['mean'] = df_scores[folds].mean(axis=1)\n",
    "    display(df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "299b1c07-a321-4b22-8f69-488df7c99059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>abs_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98144</th>\n",
       "      <td>0.049287</td>\n",
       "      <td>0.016362</td>\n",
       "      <td>3.292516e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32451</th>\n",
       "      <td>0.035998</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>3.151184e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377278</th>\n",
       "      <td>0.042814</td>\n",
       "      <td>0.017530</td>\n",
       "      <td>2.528422e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200315</th>\n",
       "      <td>0.026616</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>2.447865e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380982</th>\n",
       "      <td>0.035859</td>\n",
       "      <td>0.011530</td>\n",
       "      <td>2.432926e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92737</th>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>4.039202e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96271</th>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>4.000115e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267932</th>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>3.554469e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32159</th>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>3.474792e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133392</th>\n",
       "      <td>0.004637</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>3.197978e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143014 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          y_test    y_pred      abs_diff\n",
       "98144   0.049287  0.016362  3.292516e-02\n",
       "32451   0.035998  0.004487  3.151184e-02\n",
       "377278  0.042814  0.017530  2.528422e-02\n",
       "200315  0.026616  0.002138  2.447865e-02\n",
       "380982  0.035859  0.011530  2.432926e-02\n",
       "...          ...       ...           ...\n",
       "92737   0.001790  0.001790  4.039202e-08\n",
       "96271   0.001989  0.001989  4.000115e-08\n",
       "267932  0.002065  0.002065  3.554469e-08\n",
       "32159   0.003165  0.003165  3.474792e-08\n",
       "133392  0.004637  0.004637  3.197978e-08\n",
       "\n",
       "[143014 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [201] used 0.0000 MiB RAM in 0.19s, peaked 0.00 MiB above current, total RAM usage 2321.66 MiB\n"
     ]
    }
   ],
   "source": [
    "if X_test.shape[0] > 0:\n",
    "    df_preds = pd.DataFrame({'y_test': y_test, 'y_pred': y_pred})\n",
    "    df_preds['abs_diff'] = (df_preds['y_test'] - df_preds['y_pred']).abs()\n",
    "    display(df_preds.sort_values('abs_diff', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "04f95a61-dab8-47ec-916d-d82aff1eb5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [202] used 0.0000 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 2321.66 MiB\n"
     ]
    }
   ],
   "source": [
    "#item_to_debug = 32451\n",
    "#train_merged.reset_index().loc[item_to_debug][['stock_id', 'time_id', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d8e26169-e238-4292-873e-9f79386466e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/miniconda3/envs/optiver_volatility/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "/home/ian/miniconda3/envs/optiver_volatility/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [203] used 0.2891 MiB RAM in 1.97s, peaked 52.03 MiB above current, total RAM usage 2321.95 MiB\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if X_test.shape[0] > 0:\n",
    "        from yellowbrick.regressor import PredictionError\n",
    "        visualizer = PredictionError(est)\n",
    "        visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "        visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "        ax_subplot = visualizer.show()        \n",
    "except ModuleNotFoundError:\n",
    "    print('no yellowbrick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "784337bc-3712-4255-bbf9-a957b21feb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.4394\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                log_return1_linear\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.59%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.2224\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                log_return1_uniform\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.90%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1428\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                log_return2_linear\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0164\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                log_return2_uniform\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.02%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0060\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                log_return2_half0half1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.03%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0058\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ask_price2_var\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0055\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                size\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.08%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0054\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ask_price2_nunique\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.09%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0054\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bid_size2_nunique\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.11%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0052\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                stock_id\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.13%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0050\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ask_size2_max\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.13%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0050\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ask_size1_mean\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.16%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0048\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bid_price2_var\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.17%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0047\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bid_price1_max\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.17%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0047\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ask_price1_nunique\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.17%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0046\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ask_price2_min\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.18%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0046\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bid_size1_max\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.18%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0046\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bid_price2_nunique\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0045\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bid_size1_mean\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0045\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ask_size2_var\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0045\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ask_size1_nunique\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0045\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ask_size2_nunique\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.23%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0042\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bid_size2_mean\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.23%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0042\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bid_price2_min\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.24%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0041\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bid_size1_var\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.24%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0041\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ask_size2_mean\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ask_price2_mean\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bid_price1_nunique\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ask_size1_var\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bid_size2_max\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.25%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 18 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [204] used 0.0078 MiB RAM in 0.20s, peaked 0.00 MiB above current, total RAM usage 2321.96 MiB\n"
     ]
    }
   ],
   "source": [
    "if ENV_HOME:\n",
    "    import eli5\n",
    "    display(eli5.show_weights(est, feature_names=feature_cols, top=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0eb6411a-242a-4377-83cc-e1efc0dd12ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>importance</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.439446</th>\n",
       "      <td>log_return1_linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.222361</th>\n",
       "      <td>log_return1_uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.142786</th>\n",
       "      <td>log_return2_linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.016377</th>\n",
       "      <td>log_return2_uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005952</th>\n",
       "      <td>log_return2_half0half1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005828</th>\n",
       "      <td>ask_price2_var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005469</th>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005417</th>\n",
       "      <td>ask_price2_nunique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005350</th>\n",
       "      <td>bid_size2_nunique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005163</th>\n",
       "      <td>stock_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005014</th>\n",
       "      <td>ask_size2_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005007</th>\n",
       "      <td>ask_size1_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004784</th>\n",
       "      <td>bid_price2_var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004672</th>\n",
       "      <td>bid_price1_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004651</th>\n",
       "      <td>ask_price1_nunique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004631</th>\n",
       "      <td>ask_price2_min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004611</th>\n",
       "      <td>bid_size1_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004588</th>\n",
       "      <td>bid_price2_nunique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004539</th>\n",
       "      <td>bid_size1_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004522</th>\n",
       "      <td>ask_size2_var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004502</th>\n",
       "      <td>ask_size1_nunique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004479</th>\n",
       "      <td>ask_size2_nunique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004191</th>\n",
       "      <td>bid_size2_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004173</th>\n",
       "      <td>bid_price2_min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004132</th>\n",
       "      <td>bid_size1_var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004114</th>\n",
       "      <td>ask_size2_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004050</th>\n",
       "      <td>ask_price2_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004034</th>\n",
       "      <td>bid_price1_nunique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004033</th>\n",
       "      <td>ask_size1_var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004007</th>\n",
       "      <td>bid_size2_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.003911</th>\n",
       "      <td>bid_size1_nunique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.003797</th>\n",
       "      <td>ask_price1_var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.003677</th>\n",
       "      <td>bid_price1_min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.003565</th>\n",
       "      <td>ask_size1_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.003526</th>\n",
       "      <td>ask_price1_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.003519</th>\n",
       "      <td>bid_price2_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.003490</th>\n",
       "      <td>ask_price2_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.003447</th>\n",
       "      <td>ask_price1_min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.003434</th>\n",
       "      <td>bid_size2_var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.003299</th>\n",
       "      <td>log_return1_half0half1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.003062</th>\n",
       "      <td>bid_price2_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.002969</th>\n",
       "      <td>bid_price1_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.002912</th>\n",
       "      <td>ask_price1_mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.002895</th>\n",
       "      <td>bid_size1_min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.002801</th>\n",
       "      <td>bid_price1_var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.002770</th>\n",
       "      <td>ask_size2_min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.002175</th>\n",
       "      <td>bid_size2_min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001871</th>\n",
       "      <td>ask_size1_min</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature\n",
       "importance                        \n",
       "0.439446        log_return1_linear\n",
       "0.222361       log_return1_uniform\n",
       "0.142786        log_return2_linear\n",
       "0.016377       log_return2_uniform\n",
       "0.005952    log_return2_half0half1\n",
       "0.005828            ask_price2_var\n",
       "0.005469                      size\n",
       "0.005417        ask_price2_nunique\n",
       "0.005350         bid_size2_nunique\n",
       "0.005163                  stock_id\n",
       "0.005014             ask_size2_max\n",
       "0.005007            ask_size1_mean\n",
       "0.004784            bid_price2_var\n",
       "0.004672            bid_price1_max\n",
       "0.004651        ask_price1_nunique\n",
       "0.004631            ask_price2_min\n",
       "0.004611             bid_size1_max\n",
       "0.004588        bid_price2_nunique\n",
       "0.004539            bid_size1_mean\n",
       "0.004522             ask_size2_var\n",
       "0.004502         ask_size1_nunique\n",
       "0.004479         ask_size2_nunique\n",
       "0.004191            bid_size2_mean\n",
       "0.004173            bid_price2_min\n",
       "0.004132             bid_size1_var\n",
       "0.004114            ask_size2_mean\n",
       "0.004050           ask_price2_mean\n",
       "0.004034        bid_price1_nunique\n",
       "0.004033             ask_size1_var\n",
       "0.004007             bid_size2_max\n",
       "0.003911         bid_size1_nunique\n",
       "0.003797            ask_price1_var\n",
       "0.003677            bid_price1_min\n",
       "0.003565             ask_size1_max\n",
       "0.003526            ask_price1_max\n",
       "0.003519            bid_price2_max\n",
       "0.003490            ask_price2_max\n",
       "0.003447            ask_price1_min\n",
       "0.003434             bid_size2_var\n",
       "0.003299    log_return1_half0half1\n",
       "0.003062           bid_price2_mean\n",
       "0.002969           bid_price1_mean\n",
       "0.002912           ask_price1_mean\n",
       "0.002895             bid_size1_min\n",
       "0.002801            bid_price1_var\n",
       "0.002770             ask_size2_min\n",
       "0.002175             bid_size2_min\n",
       "0.001871             ask_size1_min"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [205] used 0.0078 MiB RAM in 0.19s, peaked 0.00 MiB above current, total RAM usage 2321.96 MiB\n"
     ]
    }
   ],
   "source": [
    "if 'feature_importances_' in dir(est):\n",
    "    feature_col = 'feature_importances_'\n",
    "elif 'coef_' in dir(est):\n",
    "    feature_col = 'coef_'\n",
    "df_features = pd.DataFrame(zip(getattr(est, feature_col), feature_cols), columns=['importance', 'feature']).set_index('importance')\n",
    "df_features.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d4f4d0-f8ee-41b2-bd0b-4d82359c54a9",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7adc3039-b6b6-4891-8366-cc9bdda5099b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [206] used 0.0000 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 2321.96 MiB\n"
     ]
    }
   ],
   "source": [
    "len(stock_ids) # expecting 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a9fd51f1-5583-4718-8edc-066c6bf9b74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ian/data/kaggle/optiver_volatility/ book_test.parquet\n",
      "[2c] 1x1, 0 nulls, is_view True, is_single_block True, is_consolidated True\n",
      "In [207] used 0.0156 MiB RAM in 0.12s, peaked 0.00 MiB above current, total RAM usage 2321.98 MiB\n"
     ]
    }
   ],
   "source": [
    "if USE_TEST_LOCAL_6_ITEMS: # True if debugging\n",
    "    # book train as a substitute\n",
    "    df_test_all = pd.read_csv(os.path.join(ROOT, 'test_local.csv'))\n",
    "    df_test_all = df_test_all.rename(columns={'target': 'train_target'})\n",
    "    TEST_FOLDER = 'book_test_local.parquet'\n",
    "    assert ENV_HOME == True\n",
    "else:\n",
    "    df_test_all = pd.read_csv(TEST_CSV)\n",
    "    if df_test_all.shape[0] == 3: # kaggle test data\n",
    "        df_test_all = df_test_all[:1] # cut out 2 rows so predictions work    \n",
    "    TEST_FOLDER = 'book_test.parquet'\n",
    "print(ROOT, TEST_FOLDER)\n",
    "df_test_all = df_test_all.set_index(['stock_id', 'time_id'])\n",
    "\n",
    "show_details(df_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "aceff1e3-860e-4986-bd16-9c467325eb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [211] used 0.2500 MiB RAM in 0.29s, peaked 0.00 MiB above current, total RAM usage 2250.90 MiB\n"
     ]
    }
   ],
   "source": [
    "test_set_predictions = []\n",
    "stock_ids_test = get_training_stock_ids(TEST_FOLDER) # all stocks by default\n",
    "\n",
    "df_test_predictions = pd.DataFrame() # prediction set to build up\n",
    "for stock_id in tqdm(stock_ids_test):\n",
    "    df_test_all_X = df_test_all.query('stock_id==@stock_id').copy()\n",
    "    test_merged = load_data_build_features(stock_id, ROOT, TEST_FOLDER, cols, df_test_all)\n",
    "    test_set_predictions_X = est.predict(test_merged.reset_index()[list(features) + ['stock_id']])\n",
    "    df_test_all_X['target'] = test_set_predictions_X\n",
    "    df_test_predictions = pd.concat((df_test_predictions, df_test_all_X))\n",
    "    \n",
    "assert df_test_all.shape[0] == df_test_predictions.shape[0], \"Expecting all rows to be predicted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d830622f-77ac-4333-9f75-b244242e4ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 1 rows to submission.csv on 2021-08-25 16:56:05.041123\n",
      "[2c] 1x2, 0 nulls, is_view True, is_single_block True, is_consolidated True\n",
      "Notebook took 0:13:35.935332 to run\n",
      "In [212] used 0.0000 MiB RAM in 0.12s, peaked 0.00 MiB above current, total RAM usage 2250.90 MiB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Writing {df_test_predictions.shape[0]} rows to submission.csv on {datetime.datetime.utcnow()}\")\n",
    "df_test_predictions.reset_index()[['row_id', 'target']].to_csv('submission.csv', index=False)\n",
    "show_details(df_test_predictions)\n",
    "print(f'Notebook took {datetime.datetime.utcnow()-t1_notebook_start} to run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "8602e701-1e85-41a7-9054-3fce950e14a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [213] used 0.0000 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 2250.90 MiB\n"
     ]
    }
   ],
   "source": [
    "if not ENV_HOME:\n",
    "    assert USE_ALL_STOCK_IDS, \"If we're on Kaggle but not using all stock_ids, we're not ready to submit, so fail here to remind me to change USSE_ALL_STOCK_IDS!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d6907-122e-41c2-b3cd-193c513038b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
