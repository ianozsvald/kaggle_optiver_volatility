{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b07f27-26af-4f9f-a474-4f4ed0a155a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENV_HOME: True, TRAIN_TEST True, USE_ALL_STOCK_IDS True, USE_TEST_LOCAL_6_ITEMS False\n",
      "NBR_FOR_SUBSET_OF_STOCK_IDS: None\n",
      "In [1] used 0.0000 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 159.38 MiB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "from numpy.random import default_rng\n",
    "RANDOM_STATE = 2 # random state for default_rng\n",
    "rng = default_rng(RANDOM_STATE)\n",
    "\n",
    "\n",
    "import random\n",
    "#import altair as alt\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "FAST_PASS = False # True for quick debug passes, not for ML\n",
    "\n",
    "# CHECKLIST for Kaggle variant\n",
    "# Use FAST_PASS True on first pass\n",
    "# USE_ALL_STOCK_IDS False to check then True\n",
    "# USE_TEST_LOCAL_6_ITEMS must be False else we override the local test data\n",
    "# TRAIN_TEST False\n",
    "# Check on Kaggle that \"internet\" is disabled\n",
    "# First run with \"USE_ALL_STOCK_IDS=False\", flip to True, Save Version, it'll take 30 mins to run\n",
    "\n",
    "# CHECKLIST for home variant\n",
    "# USE_ALL_STOCK_IDS False for fast dev, True for proper testing\n",
    "# USE_TEST_LOCAL_6_ITEMS False for fast dev, True for proper testing\n",
    "# NBR_FOR_SUBSET_OF_STOCK_IDS 4 for quick testing\n",
    "\n",
    "t1_notebook_start = datetime.datetime.utcnow()\n",
    "\n",
    "if os.environ.get('USER') == 'ian':\n",
    "    ENV_HOME = True\n",
    "    import ipython_memory_usage\n",
    "    %ipython_memory_usage_start\n",
    "    USE_ALL_STOCK_IDS = True\n",
    "    NBR_FOR_SUBSET_OF_STOCK_IDS = 4\n",
    "    TRAIN_TEST = True\n",
    "    USE_TEST_LOCAL_6_ITEMS = False # robust local testing at home\n",
    "    MEMORY_LOCATION = 'joblib_cache'\n",
    "else:\n",
    "    ENV_HOME = False\n",
    "    USE_ALL_STOCK_IDS = False # for KAGGLE on first-upload for a quick test\n",
    "    TRAIN_TEST = False\n",
    "    USE_TEST_LOCAL_6_ITEMS = False\n",
    "    NBR_FOR_SUBSET_OF_STOCK_IDS = 4\n",
    "    MEMORY_LOCATION = '/kaggle/working/joblib_cache'\n",
    "    # kaggle notes:\n",
    "    # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "    # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "if FAST_PASS:\n",
    "    USE_ALL_STOCK_IDS = False\n",
    "    TRAIN_TEST = False\n",
    "    USE_TEST_LOCAL_6_ITEMS = False # robust local testing at home TEMPORARY WHILST DEBUGGING\n",
    "\n",
    "from joblib import Memory\n",
    "memory = Memory(location=MEMORY_LOCATION, verbose=0)\n",
    "\n",
    "if USE_ALL_STOCK_IDS:\n",
    "    NBR_FOR_SUBSET_OF_STOCK_IDS=None\n",
    "print(f'ENV_HOME: {ENV_HOME}, TRAIN_TEST {TRAIN_TEST}, USE_ALL_STOCK_IDS {USE_ALL_STOCK_IDS}, USE_TEST_LOCAL_6_ITEMS {USE_TEST_LOCAL_6_ITEMS}')\n",
    "print(f'NBR_FOR_SUBSET_OF_STOCK_IDS: {NBR_FOR_SUBSET_OF_STOCK_IDS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a686d343-962d-45ab-90d1-cfeaf5a310c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility says ROOT is /home/ian/data/kaggle/optiver_volatility/\n",
      "In [2] used 0.0000 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 159.38 MiB\n"
     ]
    }
   ],
   "source": [
    "# OR PASTE IN UTILITY CODE HERE FOR KAGGLE\n",
    "from utility import make_unique_time_ids, get_training_stock_ids, rmspe_score\n",
    "from utility import ROOT, TEST_CSV, TRAIN_CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bebae2-9f9f-44b4-ac8a-6681b4866674",
   "metadata": {},
   "source": [
    "## Load train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f31ca1bb-a43b-4847-b3d7-dde9ecb027be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[59, 58, 23]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [3] used 0.2305 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 159.61 MiB\n"
     ]
    }
   ],
   "source": [
    "stock_ids = get_training_stock_ids('book_train.parquet') # all stocks by default\n",
    "\n",
    "if not USE_ALL_STOCK_IDS:\n",
    "    # choose a random subset\n",
    "    print(f\"Using a subset of {NBR_FOR_SUBSET_OF_STOCK_IDS}\")\n",
    "    rng.shuffle(stock_ids)\n",
    "    #random.shuffle(stock_ids)\n",
    "    stock_ids = stock_ids[:NBR_FOR_SUBSET_OF_STOCK_IDS]\n",
    "else:\n",
    "    print(\"Using all\")\n",
    "stock_ids[:3] # expect 59, 58, 23 if we're using all or 76, 73, 0 on the RANDOM_STATE of 1 if we don't use all stock ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "333d41e0-407c-4ffe-ab6e-f6a3e0550e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428932, 1)\n",
      "In [4] used 20.6211 MiB RAM in 0.29s, peaked 20.39 MiB above current, total RAM usage 180.23 MiB\n"
     ]
    }
   ],
   "source": [
    "df_train_all = pd.read_csv(TRAIN_CSV)\n",
    "df_train_all = df_train_all.set_index(['stock_id', 'time_id'])\n",
    "print(df_train_all.shape)\n",
    "#rows_for_stock_id_0 = df_train_all.query('stock_id == 0').shape[0]\n",
    "#rows_for_stock_id_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b852854c-236e-453e-9ae6-d598cf6d5652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2c] 428,932x1, 0 nulls, is_view True, is_single_block True, is_consolidated True\n",
      "In [5] used 0.0000 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 180.23 MiB\n"
     ]
    }
   ],
   "source": [
    "def show_details(df):\n",
    "    try:\n",
    "        nbr_index_levels = len(df.index.levels)\n",
    "    except AttributeError:\n",
    "        nbr_index_levels = 1\n",
    "    nbr_nulls = df.isnull().sum().sum()\n",
    "    #nulls_msg = \"Has no nulls\"\n",
    "    #if nbr_nulls==0:\n",
    "    nulls_msg = f\"{nbr_nulls} nulls\"\n",
    "    is_view_msg = f'is_view {df_train_all._data.is_view}'\n",
    "    is_single_block_msg = f'is_single_block {df_train_all._data.is_single_block}'\n",
    "    is_consolidated_msg = f'is_consolidated {df_train_all._data.is_consolidated()}'    \n",
    "    print(f'[{nbr_index_levels}c] {df.shape[0]:,}x{df.shape[1]:,}, {nulls_msg}, {is_view_msg}, {is_single_block_msg}, {is_consolidated_msg}')\n",
    "\n",
    "show_details(df_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "350685ba-87de-4df2-ae72-a8bc0105de27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [6] used 0.2891 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 180.52 MiB\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    all_time_ids = df_train_all.reset_index().time_id.unique()\n",
    "    rng.shuffle(all_time_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b38a9b7-0497-43ab-99ba-d59b28684f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [7] used 178.5117 MiB RAM in 0.30s, peaked 0.00 MiB above current, total RAM usage 359.04 MiB\n"
     ]
    }
   ],
   "source": [
    "def load_book(ROOT, filename, stock_id):\n",
    "    df_book_train_stock_X = pd.read_parquet(os.path.join(ROOT, f\"{filename}/stock_id={stock_id}\"))\n",
    "    df_book_train_stock_X[\"stock_id\"] = stock_id\n",
    "    df_book_train_stock_X = df_book_train_stock_X.set_index(['stock_id', 'time_id'])\n",
    "    return df_book_train_stock_X\n",
    "\n",
    "df_book_train_stock_X = load_book(ROOT, 'book_train.parquet', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "079f3c35-eda1-43c1-bcc5-6c9d60ff5ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ask_size1_nunique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>5</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ask_size1_nunique\n",
       "stock_id time_id                   \n",
       "0        5                       67\n",
       "         11                      26\n",
       "         16                      22\n",
       "         31                      30\n",
       "         62                      54"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [8] used 97.9102 MiB RAM in 0.47s, peaked 40.14 MiB above current, total RAM usage 456.95 MiB\n"
     ]
    }
   ],
   "source": [
    "# make feature columns\n",
    "def make_features_stats(df_book, agg_type, cols):\n",
    "    features_var1 = df_book.groupby(['stock_id', 'time_id'])[cols].agg(agg_type)\n",
    "    #print(type(features_var1))\n",
    "    if isinstance(features_var1, pd.Series):\n",
    "        # .size yields a series not a df\n",
    "        #features_var1.name = str(agg_type)\n",
    "        features_var1 = pd.DataFrame(features_var1, columns=[agg_type])\n",
    "        #pass\n",
    "    else:\n",
    "        features_var1_col_names = [f\"{col}_{agg_type}\" for col in cols]\n",
    "        features_var1.columns = features_var1_col_names\n",
    "    return features_var1\n",
    "\n",
    "if True: # lightweight tests\n",
    "    df_book_train_stock_X = load_book(ROOT, 'book_train.parquet', 0)\n",
    "    display(make_features_stats(df_book_train_stock_X, 'nunique', ['ask_size1']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3bfc334-1eb5-4323-bd2c-69cb5691a8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [9] used -15.4062 MiB RAM in 0.10s, peaked 0.00 MiB above current, total RAM usage 441.54 MiB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#def realized_volatility(series_log_return):\n",
    "#    return np.sqrt(np.sum(series_log_return**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faf1a31f-30c3-4ada-a2be-56d5b18f5331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.148036786359453\n",
      "In [10] used -3.4805 MiB RAM in 0.11s, peaked 3.48 MiB above current, total RAM usage 438.06 MiB\n"
     ]
    }
   ],
   "source": [
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff()\n",
    "\n",
    "def _realized_volatility_weighted_sub(ser, weights):\n",
    "    ser_weighted = ser * weights\n",
    "    return np.sqrt(np.sum(ser_weighted**2))\n",
    "\n",
    "def realized_volatility_weighted(ser, weights_type):\n",
    "    \"\"\"Weighted volatility\"\"\"\n",
    "    # as a numpy array\n",
    "    # we drop from 12us to 3us by adding @njit to the _sub function\n",
    "    # we can't make _sub a closure, it loses all compilation benefits\n",
    "    # and we can't add njit(cache=True) in Jupyter as it can't\n",
    "    # find a cache location    \n",
    "    # as a Series we have 5us and 15us w/wo @njit respectively\n",
    "    if isinstance(ser, pd.Series):\n",
    "        ser = ser.to_numpy()\n",
    "    nbr_items = ser.shape[0]\n",
    "    if weights_type == 'uniform':\n",
    "        weights = np.ones(nbr_items)\n",
    "    elif weights_type == 'linear':\n",
    "        weights = np.linspace(0.1, 1, nbr_items) # linear increasing weight\n",
    "    elif weights_type == 'half0half1':\n",
    "        half_way = int(ser.shape[0] / 2)\n",
    "        weights = np.concatenate((np.zeros(half_way), np.ones(ser.shape[0] - half_way))) # 0s then 1s weight\n",
    "    elif weights_type == 'geom':\n",
    "        weights = np.geomspace(0.01, 1, nbr_items) # geometric increase\n",
    "    #assert isinstance(weights_type, str) == False, f\"Must not be a string like '{weights}' at this point\"\n",
    "    return _realized_volatility_weighted_sub(ser, weights)\n",
    "\n",
    "if True:\n",
    "    series_log_return = pd.Series(np.linspace(0, 1, 600))\n",
    "    print(realized_volatility_weighted(series_log_return, weights_type=\"uniform\"))\n",
    "\n",
    "    #%timeit realized_volatility_weighted(series_log_return, weights_type=\"uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d530b07-9a93-4b78-bcb6-7cf4a4fbcbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>realized_vol_log_return_wap2_linear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>5</th>\n",
       "      <td>0.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  realized_vol_log_return_wap2_linear\n",
       "stock_id time_id                                     \n",
       "0        5                                   0.004500\n",
       "         11                                  0.001749"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [12] used 30.3789 MiB RAM in 2.53s, peaked 93.36 MiB above current, total RAM usage 361.21 MiB\n"
     ]
    }
   ],
   "source": [
    "def make_wap(df_book_data, num=1, wap_colname=\"wap\"):\n",
    "    \"\"\"Modifies df_book_data\"\"\"\n",
    "    assert num==1 or num==2\n",
    "    wap_numerator = (df_book_data[f'bid_price{num}'] * df_book_data[f'ask_size{num}'] +\n",
    "                                     df_book_data[f'ask_price{num}'] * df_book_data[f'bid_size{num}'])\n",
    "    wap_denominator = df_book_data[f'bid_size{num}'] + df_book_data[f'ask_size{num}']\n",
    "    df_book_data[wap_colname] = wap_numerator / wap_denominator\n",
    "\n",
    "\n",
    "def make_realized_volatility(df_book_data, col, weights=\"uniform\"):\n",
    "    \"\"\"Consume wap column\"\"\"\n",
    "    new_name = \"realized_vol_log_return_\" + col + \"_\" + weights\n",
    "    df_book_data[new_name] = df_book_data.groupby(['stock_id', 'time_id'])[col].apply(log_return)\n",
    "    df_book_data = df_book_data[~df_book_data[new_name].isnull()]\n",
    "    df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['stock_id', 'time_id'])[new_name].agg(realized_volatility_weighted, weights))\n",
    "    return df_realized_vol_per_stock\n",
    "\n",
    "if True: # lightweight tests\n",
    "    df_book_train_stock_X = load_book(ROOT, 'book_train.parquet', 0)\n",
    "    make_wap(df_book_train_stock_X, 2, wap_colname=\"wap2\") # adds 'wap' column\n",
    "    df_realized_vol_per_stockX = make_realized_volatility(df_book_train_stock_X, col=\"wap2\", weights='linear')\n",
    "    display(df_realized_vol_per_stockX.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eab6adc4-9b47-482e-af1c-43206a997db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [13] used 0.0078 MiB RAM in 0.11s, peaked 0.00 MiB above current, total RAM usage 361.22 MiB\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    def make_volatility_ask_bid_diff(df_book_data, col='ask1_bid1_diff', weights='uniform'):\n",
    "                                     #new_name='ask1_bid1_diff_log_ret'):\n",
    "        #new_name = col + '_log_return' # 'ask1_bid1_diff'\n",
    "        new_name = col + \"_log_return_\" + weights\n",
    "        df_book_data[new_name] = df_book_data.groupby(['stock_id', 'time_id'])[col].apply(log_return)\n",
    "        df_book_data = df_book_data[~df_book_data[new_name].isnull()]\n",
    "        # makes a new dataframe\n",
    "        df_realized_vol_ask_bid_diff_per_stock =  pd.DataFrame(df_book_data.groupby(['stock_id', 'time_id'])[new_name].agg(realized_volatility_weighted, weights))\n",
    "        return df_realized_vol_ask_bid_diff_per_stock\n",
    "\n",
    "\n",
    "    if True: # lightweight tests\n",
    "        df_book_train_stock_XX = pd.read_parquet(os.path.join(ROOT, f\"book_train.parquet/stock_id=0\"))\n",
    "        df_book_train_stock_XX[\"stock_id\"] = 0\n",
    "        df_book_train_stock_XX = df_book_train_stock_XX.set_index(['stock_id', 'time_id'])\n",
    "        df_book_train_stock_XX['ask1_bid1_diff'] = (df_book_train_stock_XX['ask_price1'] / df_book_train_stock_XX['bid_price1']) - 1\n",
    "        df_realized_vol_ask_bid_diff_per_stock = make_volatility_ask_bid_diff(df_book_train_stock_XX, weights='linear')\n",
    "        #make_wap(df_book_train_stock_XX, 2) # adds 'wap' column\n",
    "        #df_realized_vol_per_stockXX = make_realized_volatility(df_book_train_stock_XX, log_return_name=\"log_return2\", weights='linear')\n",
    "        display(df_realized_vol_ask_bid_diff_per_stock.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c8e30b3-63e1-4bd4-9138-a818de0a0cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>realized_vol_log_return_ask1_bid1_diff_linear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>5</th>\n",
       "      <td>2.032456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.646661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.050446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.069932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2.013495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  realized_vol_log_return_ask1_bid1_diff_linear\n",
       "stock_id time_id                                               \n",
       "0        5                                             2.032456\n",
       "         11                                            1.646661\n",
       "         16                                            1.050446\n",
       "         31                                            1.069932\n",
       "         62                                            2.013495"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [14] used -7.5273 MiB RAM in 2.62s, peaked 81.75 MiB above current, total RAM usage 353.70 MiB\n"
     ]
    }
   ],
   "source": [
    "if True: # lightweight tests\n",
    "    df_book_train_stock_X = load_book(ROOT, 'book_train.parquet', 0)\n",
    "    df_book_train_stock_X['ask1_bid1_diff'] = (df_book_train_stock_X['ask_price1'] / df_book_train_stock_X['bid_price1']) - 1\n",
    "    df_realized_vol_ask_bid_diff_per_stock = make_realized_volatility(df_book_train_stock_X, col='ask1_bid1_diff', weights='linear')\n",
    "    #make_wap(df_book_train_stock_XX, 2) # adds 'wap' column\n",
    "    #df_realized_vol_per_stockXX = make_realized_volatility(df_book_train_stock_XX, log_return_name=\"log_return2\", weights='linear')\n",
    "    display(df_realized_vol_ask_bid_diff_per_stock.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48004be8-218d-4429-aa0b-b0501de94a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>bid_price1_var</th>\n",
       "      <th>ask_price1_var</th>\n",
       "      <th>bid_price2_var</th>\n",
       "      <th>ask_price2_var</th>\n",
       "      <th>bid_size1_var</th>\n",
       "      <th>ask_size1_var</th>\n",
       "      <th>bid_size2_var</th>\n",
       "      <th>ask_size2_var</th>\n",
       "      <th>bid_price1_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>realized_vol_log_return_wap_linear</th>\n",
       "      <th>realized_vol_log_return_wap2_linear</th>\n",
       "      <th>realized_vol_log_return_wap_half0half1</th>\n",
       "      <th>realized_vol_log_return_wap2_half0half1</th>\n",
       "      <th>realized_vol_log_return_ask1_bid1_diff_uniform</th>\n",
       "      <th>realized_vol_log_return_ask2_bid2_diff_uniform</th>\n",
       "      <th>realized_vol_log_return_ask1_bid2_diff_uniform</th>\n",
       "      <th>realized_vol_log_return_ask2_bid1_diff_uniform</th>\n",
       "      <th>trade_size_count</th>\n",
       "      <th>trade_order_count_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">31</th>\n",
       "      <th>5</th>\n",
       "      <td>0.004113</td>\n",
       "      <td>2.692188e-06</td>\n",
       "      <td>2.681080e-06</td>\n",
       "      <td>2.692195e-06</td>\n",
       "      <td>2.681076e-06</td>\n",
       "      <td>2.238556e+07</td>\n",
       "      <td>3.623230e+07</td>\n",
       "      <td>1.806015e+07</td>\n",
       "      <td>1.258087e+07</td>\n",
       "      <td>0.997129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0.003343</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.981440</td>\n",
       "      <td>0.408084</td>\n",
       "      <td>0.574537</td>\n",
       "      <td>0.574467</td>\n",
       "      <td>50</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000956</td>\n",
       "      <td>2.032095e-08</td>\n",
       "      <td>2.031816e-08</td>\n",
       "      <td>2.032095e-08</td>\n",
       "      <td>2.031816e-08</td>\n",
       "      <td>4.570735e+07</td>\n",
       "      <td>1.831557e+08</td>\n",
       "      <td>1.766419e+07</td>\n",
       "      <td>1.628047e+08</td>\n",
       "      <td>1.000411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002127</td>\n",
       "      <td>1.158020e-06</td>\n",
       "      <td>1.158066e-06</td>\n",
       "      <td>1.157965e-06</td>\n",
       "      <td>1.157958e-06</td>\n",
       "      <td>1.800935e+08</td>\n",
       "      <td>2.033910e+08</td>\n",
       "      <td>6.437634e+08</td>\n",
       "      <td>2.730231e+08</td>\n",
       "      <td>0.999483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.002725</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.002442</td>\n",
       "      <td>12</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.003748</td>\n",
       "      <td>4.796240e-07</td>\n",
       "      <td>4.796240e-07</td>\n",
       "      <td>4.796240e-07</td>\n",
       "      <td>4.796240e-07</td>\n",
       "      <td>8.473959e+07</td>\n",
       "      <td>4.096441e+07</td>\n",
       "      <td>3.710387e+07</td>\n",
       "      <td>1.243901e+08</td>\n",
       "      <td>0.994919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.001573</td>\n",
       "      <td>2.165609e-07</td>\n",
       "      <td>2.166966e-07</td>\n",
       "      <td>2.165884e-07</td>\n",
       "      <td>2.167498e-07</td>\n",
       "      <td>1.690191e+08</td>\n",
       "      <td>1.316160e+08</td>\n",
       "      <td>6.440620e+07</td>\n",
       "      <td>7.843908e+07</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>0.980168</td>\n",
       "      <td>0.406911</td>\n",
       "      <td>0.573358</td>\n",
       "      <td>0.573510</td>\n",
       "      <td>21</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    target  bid_price1_var  ask_price1_var  bid_price2_var  \\\n",
       "stock_id time_id                                                             \n",
       "31       5        0.004113    2.692188e-06    2.681080e-06    2.692195e-06   \n",
       "         11       0.000956    2.032095e-08    2.031816e-08    2.032095e-08   \n",
       "         16       0.002127    1.158020e-06    1.158066e-06    1.157965e-06   \n",
       "         31       0.003748    4.796240e-07    4.796240e-07    4.796240e-07   \n",
       "         62       0.001573    2.165609e-07    2.166966e-07    2.165884e-07   \n",
       "\n",
       "                  ask_price2_var  bid_size1_var  ask_size1_var  bid_size2_var  \\\n",
       "stock_id time_id                                                                \n",
       "31       5          2.681076e-06   2.238556e+07   3.623230e+07   1.806015e+07   \n",
       "         11         2.031816e-08   4.570735e+07   1.831557e+08   1.766419e+07   \n",
       "         16         1.157958e-06   1.800935e+08   2.033910e+08   6.437634e+08   \n",
       "         31         4.796240e-07   8.473959e+07   4.096441e+07   3.710387e+07   \n",
       "         62         2.167498e-07   1.690191e+08   1.316160e+08   6.440620e+07   \n",
       "\n",
       "                  ask_size2_var  bid_price1_mean  ...  \\\n",
       "stock_id time_id                                  ...   \n",
       "31       5         1.258087e+07         0.997129  ...   \n",
       "         11        1.628047e+08         1.000411  ...   \n",
       "         16        2.730231e+08         0.999483  ...   \n",
       "         31        1.243901e+08         0.994919  ...   \n",
       "         62        7.843908e+07         0.999969  ...   \n",
       "\n",
       "                  realized_vol_log_return_wap_linear  \\\n",
       "stock_id time_id                                       \n",
       "31       5                                  0.002836   \n",
       "         11                                 0.000324   \n",
       "         16                                 0.001487   \n",
       "         31                                 0.001739   \n",
       "         62                                 0.001121   \n",
       "\n",
       "                  realized_vol_log_return_wap2_linear  \\\n",
       "stock_id time_id                                        \n",
       "31       5                                   0.003074   \n",
       "         11                                  0.001223   \n",
       "         16                                  0.002725   \n",
       "         31                                  0.004240   \n",
       "         62                                  0.001908   \n",
       "\n",
       "                  realized_vol_log_return_wap_half0half1  \\\n",
       "stock_id time_id                                           \n",
       "31       5                                      0.003343   \n",
       "         11                                     0.000292   \n",
       "         16                                     0.001602   \n",
       "         31                                     0.002036   \n",
       "         62                                     0.000994   \n",
       "\n",
       "                  realized_vol_log_return_wap2_half0half1  \\\n",
       "stock_id time_id                                            \n",
       "31       5                                       0.003636   \n",
       "         11                                      0.000252   \n",
       "         16                                      0.002811   \n",
       "         31                                      0.005161   \n",
       "         62                                      0.001528   \n",
       "\n",
       "                  realized_vol_log_return_ask1_bid1_diff_uniform  \\\n",
       "stock_id time_id                                                   \n",
       "31       5                                              0.981440   \n",
       "         11                                             0.001358   \n",
       "         16                                             0.002366   \n",
       "         31                                             0.003457   \n",
       "         62                                             0.980168   \n",
       "\n",
       "                  realized_vol_log_return_ask2_bid2_diff_uniform  \\\n",
       "stock_id time_id                                                   \n",
       "31       5                                              0.408084   \n",
       "         11                                             0.001292   \n",
       "         16                                             0.002362   \n",
       "         31                                             0.003353   \n",
       "         62                                             0.406911   \n",
       "\n",
       "                  realized_vol_log_return_ask1_bid2_diff_uniform  \\\n",
       "stock_id time_id                                                   \n",
       "31       5                                              0.574537   \n",
       "         11                                             0.001260   \n",
       "         16                                             0.002336   \n",
       "         31                                             0.003121   \n",
       "         62                                             0.573358   \n",
       "\n",
       "                  realized_vol_log_return_ask2_bid1_diff_uniform  \\\n",
       "stock_id time_id                                                   \n",
       "31       5                                              0.574467   \n",
       "         11                                             0.001261   \n",
       "         16                                             0.002442   \n",
       "         31                                             0.003269   \n",
       "         62                                             0.573510   \n",
       "\n",
       "                  trade_size_count  trade_order_count_sum  \n",
       "stock_id time_id                                           \n",
       "31       5                      50                    582  \n",
       "         11                     10                     43  \n",
       "         16                     12                     69  \n",
       "         31                     30                    149  \n",
       "         62                     21                    179  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [15] used 40.9141 MiB RAM in 39.20s, peaked 527.36 MiB above current, total RAM usage 394.61 MiB\n"
     ]
    }
   ],
   "source": [
    "#@memory.cache\n",
    "def load_data_build_features(stock_id, ROOT, book_filename, trade_filename, cols, df_target):\n",
    "    # filename e.g. book_train.parquet\n",
    "    assert isinstance(stock_id, int)\n",
    "    #df_book_stock_X = pd.read_parquet(\n",
    "    #    os.path.join(ROOT, f\"{book_filename}/stock_id={stock_id}\")\n",
    "    #)\n",
    "    #df_book_stock_X[\"stock_id\"] = stock_id\n",
    "    #df_book_stock_X = df_book_stock_X.set_index(['stock_id', 'time_id'])\n",
    "    df_book_stock_X = load_book(ROOT, book_filename, stock_id)\n",
    "    #assert df_book_train_stock_X.shape[0] > rows_for_stock_id_0, (df_book_train_stock_X.shape[0], rows_for_stock_id_0)\n",
    "    \n",
    "    df_trade_stock_X = pd.read_parquet(\n",
    "        os.path.join(ROOT, f\"{trade_filename}/stock_id={stock_id}\")\n",
    "    )\n",
    "    df_trade_stock_X[\"stock_id\"] = stock_id\n",
    "    df_trade_stock_X = df_trade_stock_X.set_index(['stock_id', 'time_id'])\n",
    "    \n",
    "    #df_book_train_stock_X_gt500 = df_book_train_stock_X.query(\"seconds_in_bucket>500\").copy()\n",
    "    #df_realized_vol_per_stock_short500 = add_wap_make_realized_volatility(df_book_train_stock_X_gt500, log_return_name='log_return_gt500sec')\n",
    "    #df_book_train_stock_X_gt300 = df_book_train_stock_X.query(\"seconds_in_bucket>300\").copy()\n",
    "    #df_realized_vol_per_stock_short300 = add_wap_make_realized_volatility(df_book_train_stock_X_gt300, log_return_name='log_return_gt300sec')\n",
    "    if True:\n",
    "        make_wap(df_book_stock_X, 2, \"wap2\") \n",
    "        df_realized_vol_per_stock_wap2_uniform = make_realized_volatility(df_book_stock_X, col=\"wap2\", weights='uniform')    \n",
    "        df_realized_vol_per_stock_wap2_linear = make_realized_volatility(df_book_stock_X, col=\"wap2\", weights='linear')\n",
    "        df_realized_vol_per_stock_wap2_half0half1 = make_realized_volatility(df_book_stock_X, col=\"wap2\", weights='half0half1')\n",
    "        make_wap(df_book_stock_X, 1, \"wap\") # adds 'wap' column\n",
    "        df_realized_vol_per_stock_wap1_uniform = make_realized_volatility(df_book_stock_X, col=\"wap\", weights='uniform')\n",
    "        df_realized_vol_per_stock_wap1_linear = make_realized_volatility(df_book_stock_X, col=\"wap\", weights='linear')\n",
    "        df_realized_vol_per_stock_wap1_half0half1 = make_realized_volatility(df_book_stock_X, col=\"wap\", weights='half0half1')\n",
    "\n",
    "        features_var1 = make_features_stats(df_book_stock_X, 'var', cols)\n",
    "        features_mean1 = make_features_stats(df_book_stock_X, 'mean', cols)\n",
    "        features_size1 = make_features_stats(df_book_stock_X, 'size', cols)\n",
    "        features_min1 = make_features_stats(df_book_stock_X, 'min', cols)\n",
    "        features_max1 = make_features_stats(df_book_stock_X, 'max', cols)\n",
    "        features_nunique1 = make_features_stats(df_book_stock_X, 'nunique', cols)\n",
    "\n",
    "        if False:\n",
    "            df_book_stock_X['ask1_bid1_diff'] = (df_book_stock_X['ask_price1'] / df_book_stock_X['bid_price1']) - 1\n",
    "            df_realized_vol_ask1_bid1_diff_per_stock = make_volatility_ask_bid_diff(df_book_stock_X, col='ask1_bid1_diff')\n",
    "            df_realized_vol_ask1_bid1_diff_per_stock_linear = make_volatility_ask_bid_diff(df_book_stock_X, col='ask1_bid1_diff', weights='linear')\n",
    "            df_realized_vol_ask1_bid1_diff_per_stock_half0half1 = make_volatility_ask_bid_diff(df_book_stock_X, col='ask1_bid1_diff', weights='half0half1')\n",
    "            df_book_stock_X['ask2_bid2_diff'] = (df_book_stock_X['ask_price2'] / df_book_stock_X['bid_price2']) - 1\n",
    "            df_realized_vol_ask2_bid2_diff_per_stock = make_volatility_ask_bid_diff(df_book_stock_X, col='ask2_bid2_diff')\n",
    "            df_realized_vol_ask2_bid2_diff_per_stock_linear = make_volatility_ask_bid_diff(df_book_stock_X, col='ask2_bid2_diff', weights='linear')\n",
    "            df_realized_vol_ask2_bid2_diff_per_stock_half0half1 = make_volatility_ask_bid_diff(df_book_stock_X, col='ask2_bid2_diff', weights='half0half1')\n",
    "            df_book_stock_X['ask1_bid2_diff'] = (df_book_stock_X['ask_price1'] / df_book_stock_X['bid_price2']) - 1\n",
    "            df_realized_vol_ask1_bid2_diff_per_stock = make_volatility_ask_bid_diff(df_book_stock_X, col='ask1_bid2_diff')\n",
    "            df_book_stock_X['ask2_bid1_diff'] = (df_book_stock_X['ask_price2'] / df_book_stock_X['bid_price1']) - 1\n",
    "            df_realized_vol_ask2_bid1_diff_per_stock = make_volatility_ask_bid_diff(df_book_stock_X, col='ask2_bid1_diff')\n",
    "        df_book_stock_X['ask1_bid1_diff'] = (df_book_stock_X['ask_price1'] / df_book_stock_X['bid_price1']) - 1\n",
    "        df_realized_vol_ask1_bid1_diff_per_stock = make_realized_volatility(df_book_stock_X, col='ask1_bid1_diff')\n",
    "        df_realized_vol_ask1_bid1_diff_per_stock_linear = make_realized_volatility(df_book_stock_X, col='ask1_bid1_diff', weights='linear')\n",
    "        df_realized_vol_ask1_bid1_diff_per_stock_half0half1 = make_realized_volatility(df_book_stock_X, col='ask1_bid1_diff', weights='half0half1')\n",
    "        df_book_stock_X['ask2_bid2_diff'] = (df_book_stock_X['ask_price2'] / df_book_stock_X['bid_price2']) - 1\n",
    "        df_realized_vol_ask2_bid2_diff_per_stock = make_realized_volatility(df_book_stock_X, col='ask2_bid2_diff')\n",
    "        df_realized_vol_ask2_bid2_diff_per_stock_linear = make_realized_volatility(df_book_stock_X, col='ask2_bid2_diff', weights='linear')\n",
    "        df_realized_vol_ask2_bid2_diff_per_stock_half0half1 = make_realized_volatility(df_book_stock_X, col='ask2_bid2_diff', weights='half0half1')\n",
    "        df_book_stock_X['ask1_bid2_diff'] = (df_book_stock_X['ask_price1'] / df_book_stock_X['bid_price2']) - 1\n",
    "        df_realized_vol_ask1_bid2_diff_per_stock = make_realized_volatility(df_book_stock_X, col='ask1_bid2_diff')\n",
    "        df_book_stock_X['ask2_bid1_diff'] = (df_book_stock_X['ask_price2'] / df_book_stock_X['bid_price1']) - 1\n",
    "        df_realized_vol_ask2_bid1_diff_per_stock = make_realized_volatility(df_book_stock_X, col='ask2_bid1_diff')\n",
    "    else:\n",
    "        features_var1 = make_features_stats(df_book_stock_X, 'var', cols)\n",
    "        \n",
    "    #breakpoint()\n",
    "    # trade stats\n",
    "    df_trade_basic_stats = df_trade_stock_X.groupby(['stock_id', 'time_id']).agg(trade_size_count=pd.NamedAgg('size', 'count'), trade_order_count_sum=pd.NamedAgg('order_count', 'sum'))\n",
    "\n",
    "    df_train_stock_X = df_target.query('stock_id == @stock_id')\n",
    "    if True:\n",
    "        to_merge_book = [df_train_stock_X, \n",
    "                    features_var1, features_mean1, features_size1, \n",
    "                    features_min1, features_max1, features_nunique1,\n",
    "                    df_realized_vol_ask1_bid1_diff_per_stock_linear,\n",
    "                    df_realized_vol_ask1_bid1_diff_per_stock_half0half1,\n",
    "                     df_realized_vol_ask2_bid2_diff_per_stock_linear,\n",
    "                     df_realized_vol_ask2_bid2_diff_per_stock_half0half1,\n",
    "                    df_realized_vol_per_stock_wap1_uniform,\n",
    "                    df_realized_vol_per_stock_wap2_uniform,\n",
    "                    df_realized_vol_per_stock_wap1_linear,\n",
    "                    df_realized_vol_per_stock_wap2_linear,\n",
    "                    df_realized_vol_per_stock_wap1_half0half1,\n",
    "                    df_realized_vol_per_stock_wap2_half0half1,\n",
    "                    df_realized_vol_ask1_bid1_diff_per_stock,\n",
    "                    df_realized_vol_ask2_bid2_diff_per_stock,\n",
    "                    df_realized_vol_ask1_bid2_diff_per_stock,\n",
    "                    df_realized_vol_ask2_bid1_diff_per_stock,]\n",
    "        to_merge_trade = [df_trade_basic_stats]\n",
    "    else:\n",
    "        to_merge_book = [df_train_stock_X, features_var1]\n",
    "        to_merge_trade = [df_trade_basic_stats]\n",
    "\n",
    "    # some trade datasets are missing some time_ids, making the join a mess\n",
    "    # we reindex and make the choice to fillna 0\n",
    "    to_merge_trade = [to_merge_tr.reindex(to_merge_book[0].index, fill_value=0) for to_merge_tr in to_merge_trade]\n",
    "    #to_merge_trade = [to_merge_tr.reindex(to_merge_book[0].index, fill_value=0).fillna(0) for to_merge_tr in to_merge_trade]\n",
    "    \n",
    "    row_lengths = [df.shape[0] for df in to_merge_book]\n",
    "    assert len(set(row_lengths)) == 1, f\"row_lengths are different for stock {stock_id}: {row_lengths}\" # should all be same length\n",
    "    to_merge = to_merge_book + to_merge_trade\n",
    "    for idx, item_to_merge in enumerate(to_merge):\n",
    "        assert item_to_merge.index.names == ['stock_id', 'time_id'], f\"We must have the same index on idx {idx}\"\n",
    "    train_merged = pd.concat(to_merge, axis=1)\n",
    "                             \n",
    "    if 'target' in train_merged.columns:\n",
    "        features = train_merged.drop(columns='target').columns\n",
    "        #print(features)\n",
    "        assert len(set(features)) == len(features), f\"Feature duplication! {len(set(features))} vs {len(features)}\"\n",
    "\n",
    "    return train_merged\n",
    "\n",
    "#if 'memory' in dir():\n",
    "#    # only setup local cache if we're running locally in development\n",
    "#    load_data_build_features = memory.cache(load_data_build_features)\n",
    "    \n",
    "cols = ['bid_price1', 'ask_price1', 'bid_price2', 'ask_price2',] \n",
    "cols += ['bid_size1', 'ask_size1', 'bid_size2', 'ask_size2']\n",
    "\n",
    "if True:    \n",
    "    # test...\n",
    "    train_mergedXX = load_data_build_features(31, ROOT, 'book_train.parquet', 'trade_train.parquet', cols, df_train_all)\n",
    "    display(train_mergedXX.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce31de7-961b-440f-9eee-824c3b4e1aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating over 112 stocks:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  4.3min\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "print(f'Iterating over {len(stock_ids)} stocks:')\n",
    "\n",
    "all_train_merged = Parallel(n_jobs=-1, verbose=10)(delayed(load_data_build_features)(stock_id, ROOT, 'book_train.parquet', 'trade_train.parquet', cols, df_train_all) for stock_id in stock_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a8bbd-ea61-4121-a0f7-a303cb0940d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all the partial results back together\n",
    "train_merged = pd.concat(all_train_merged)\n",
    "show_details(train_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e53e2a-2e5f-48e3-9ada-0ab519af8bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8c58d2-9e7e-41a7-8ecb-035762d33e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_merged.drop(columns='target').columns\n",
    "print(features)\n",
    "assert len(set(features)) == len(features), f\"{len(set(features))} vs {len(features)} features, we should not have any duplicates\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa604e88-0b6f-438a-9143-9bce7289a0a1",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc812dd3-119c-4dab-95ff-0c2de1bb5cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = list(features) + ['stock_id']\n",
    "print(feature_cols)\n",
    "if not TRAIN_TEST:\n",
    "    # probably we're building on Kaggle\n",
    "    # we need all data for train, there is no test set\n",
    "    df_train_merged = train_merged.reset_index()[feature_cols+['time_id', 'target']]\n",
    "    X_train = df_train_merged.drop(columns=['target', 'time_id'])\n",
    "    y_train = df_train_merged['target']\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    #X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e707413-28fc-4963-8281-f5c6a9d49cd7",
   "metadata": {},
   "source": [
    "# ML on a train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fee6800-336e-4e6e-84f9-ff513a424f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting \n",
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d785c-fb6b-4421-a939-9c88f9a5774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#est = LinearRegression()\n",
    "#est = RandomForestRegressor(n_estimators=10, n_jobs=-1, random_state=RANDOM_STATE) # default n_estimators==100\n",
    "#est = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=RANDOM_STATE) # default n_estimators==100\n",
    "#est = GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
    "#est = HistGradientBoostingRegressor(random_state=RANDOM_STATE)\n",
    "\n",
    "# https://xgboost.readthedocs.io/en/latest/python/python_api.html\n",
    "#tree_method='exact' default\n",
    "#est = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "#est = xgb.XGBRegressor(tree_method='hist', )\n",
    "est = xgb.XGBRegressor( )\n",
    "\n",
    "#est = LGBMRegressor()\n",
    "\n",
    "if not TRAIN_TEST:\n",
    "    print('Fitting estimator on all the data')\n",
    "    est.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73ac0af-32ed-4d00-91da-2dc14c1e28c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(f\"USE_ALL_STOCK_IDS: {USE_ALL_STOCK_IDS}\")\n",
    "\n",
    "print(f\"{df_train_all.reset_index().stock_id.unique().shape[0]} unique stock ids\")\n",
    "print(f\"Features:\", feature_cols)\n",
    "print(est)\n",
    "\n",
    "scores = []\n",
    "if TRAIN_TEST:\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html\n",
    "    # note the splits appear to be deterministic, possibly on discovery order\n",
    "    from sklearn.model_selection import GroupKFold\n",
    "    train_merged_no_idx = train_merged.reset_index()\n",
    "    groups = train_merged_no_idx['time_id']\n",
    "    group_kfold = GroupKFold(n_splits=3)\n",
    "    X_all = train_merged_no_idx[feature_cols]\n",
    "    y_all = train_merged_no_idx['target']\n",
    "    print(group_kfold.get_n_splits(X_all, y_all, groups))\n",
    "    for train_index, test_index in group_kfold.split(X_all, y_all, groups):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X_all.loc[train_index], X_all.loc[test_index]\n",
    "        y_train, y_test = y_all.loc[train_index], y_all.loc[test_index]\n",
    "        est.fit(X_train, y_train)\n",
    "        y_pred = est.predict(X_test)\n",
    "        score = r2_score(y_test, y_pred)\n",
    "        rmspe = rmspe_score(y_test, y_pred)\n",
    "        print(f\"rmspe score {rmspe:0.3f}, r^2 score {score:0.3f} on {y_pred.shape[0]:,} predictions\")\n",
    "        scores.append({'r2': score, 'rmspe': rmspe})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999fbd6-622a-4658-b3a3-9bfa7f7ec7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(scores) > 0:\n",
    "    # only show results if we've used cross validation\n",
    "    df_scores = pd.DataFrame(scores).T\n",
    "    folds = df_scores.columns.values\n",
    "    df_scores['std'] = df_scores[folds].std(axis=1)\n",
    "    df_scores['mean'] = df_scores[folds].mean(axis=1)\n",
    "    display(df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299b1c07-a321-4b22-8f69-488df7c99059",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_TEST:\n",
    "    df_preds = pd.DataFrame({'y_test': y_test, 'y_pred': y_pred})\n",
    "    df_preds['abs_diff'] = (df_preds['y_test'] - df_preds['y_pred']).abs()\n",
    "    display(df_preds.sort_values('abs_diff', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f95a61-dab8-47ec-916d-d82aff1eb5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#item_to_debug = 32451\n",
    "#train_merged.reset_index().loc[item_to_debug][['stock_id', 'time_id', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e26169-e238-4292-873e-9f79386466e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #if X_test.shape[0] > 0:\n",
    "    if TRAIN_TEST:\n",
    "        from yellowbrick.regressor import PredictionError\n",
    "        visualizer = PredictionError(est)\n",
    "        visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "        visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "        ax_subplot = visualizer.show()        \n",
    "except ModuleNotFoundError:\n",
    "    print('no yellowbrick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784337bc-3712-4255-bbf9-a957b21feb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENV_HOME:\n",
    "    import eli5\n",
    "    display(eli5.show_weights(est, feature_names=feature_cols, top=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb6411a-242a-4377-83cc-e1efc0dd12ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'feature_importances_' in dir(est):\n",
    "    feature_col = 'feature_importances_'\n",
    "elif 'coef_' in dir(est):\n",
    "    feature_col = 'coef_'\n",
    "df_features = pd.DataFrame(zip(getattr(est, feature_col), feature_cols), columns=['importance', 'feature']).set_index('importance')\n",
    "df_features.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d4f4d0-f8ee-41b2-bd0b-4d82359c54a9",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc3039-b6b6-4891-8366-cc9bdda5099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stock_ids) # expecting 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd51f1-5583-4718-8edc-066c6bf9b74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TEST_LOCAL_6_ITEMS: # True if debugging\n",
    "    # book train as a substitute\n",
    "    df_test_all = pd.read_csv(os.path.join(ROOT, 'test_local.csv'))\n",
    "    df_test_all = df_test_all.rename(columns={'target': 'train_target'})\n",
    "    TEST_FOLDER = 'book_test_local.parquet'\n",
    "    assert ENV_HOME == True\n",
    "else:\n",
    "    df_test_all = pd.read_csv(TEST_CSV)\n",
    "    if df_test_all.shape[0] == 3: # kaggle test data\n",
    "        df_test_all = df_test_all[:1] # cut out 2 rows so predictions work    \n",
    "    TEST_FOLDER = 'book_test.parquet'\n",
    "print(ROOT, TEST_FOLDER)\n",
    "df_test_all = df_test_all.set_index(['stock_id', 'time_id'])\n",
    "\n",
    "show_details(df_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceff1e3-860e-4986-bd16-9c467325eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_predictions = []\n",
    "stock_ids_test = get_training_stock_ids(TEST_FOLDER) # all stocks by default\n",
    "\n",
    "df_test_predictions = pd.DataFrame() # prediction set to build up\n",
    "for stock_id in tqdm(stock_ids_test):\n",
    "    df_test_all_X = df_test_all.query('stock_id==@stock_id').copy()\n",
    "    test_merged = load_data_build_features(stock_id, ROOT, TEST_FOLDER, 'trade_test.parquet', cols, df_test_all)\n",
    "    test_set_predictions_X = est.predict(test_merged.reset_index()[list(features) + ['stock_id']])\n",
    "    df_test_all_X['target'] = test_set_predictions_X\n",
    "    df_test_predictions = pd.concat((df_test_predictions, df_test_all_X))\n",
    "    \n",
    "assert df_test_all.shape[0] == df_test_predictions.shape[0], \"Expecting all rows to be predicted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d830622f-77ac-4333-9f75-b244242e4ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Writing {df_test_predictions.shape[0]} rows to submission.csv on {datetime.datetime.utcnow()}\")\n",
    "df_test_predictions.reset_index()[['row_id', 'target']].to_csv('submission.csv', index=False)\n",
    "show_details(df_test_predictions)\n",
    "print(f'Notebook took {datetime.datetime.utcnow()-t1_notebook_start} to run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8602e701-1e85-41a7-9054-3fce950e14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ENV_HOME:\n",
    "    assert USE_ALL_STOCK_IDS, \"If we're on Kaggle but not using all stock_ids, we're not ready to submit, so fail here to remind me to change USSE_ALL_STOCK_IDS!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d6907-122e-41c2-b3cd-193c513038b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
